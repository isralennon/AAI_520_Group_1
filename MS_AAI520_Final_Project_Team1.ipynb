{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7846f45-e90c-44c2-8ad1-e1f8db4e3325",
   "metadata": {},
   "source": [
    "# UNIVERSITY OF SAN DIEGO - MS AAI\n",
    "## Natural Language Processing and Generative AI\n",
    "### Final Project - Team 1: Multi-Agent Financial Analysis System.\n",
    "#### By Manikandan Perumal & Israel Romero Olvera\n",
    "#### The purpose of this final project is to build a real-world financial analysis system powered by agentic AI, with the abilities of reasoning, planning, and acting based on the user's prompt. It will coordinate multiple specialized LLM agents to handle complex financial tasks end-to-end.\n",
    "#### Our Agentic AI system was developed in a folder structure that can be found in our GitHub site: https://github.com/isralennon/AAI_520_Group_1/tree/main\n",
    "#### For delivery purposes we've condensed all the code into this document, structured the following way:\n",
    "#### 1. Tools - this section contains the code in file /modules/tools.py which will perform basic RAG connections.\n",
    "#### 2. Parser - this section contains the code in file /modules/parser.py, which provides basic functionality to parse data in JSON format.\n",
    "#### 3. Memory - this section contains the code in file /modules/memory.py that handles the storage of ongoing knowledge, to provide a robust and efficient functionality.\n",
    "#### 4. Agents - this section contains the code in file /modules/subagents.py, designed to host the definitions of the main Agent class as well as our specialized subagents - the team of agents available to the main orchestrator. We developed the following team of agents:\n",
    "#### - Orchestrator - the \"Manager\" of the Agents\n",
    "#### - News Researcher - the specialist of finding financial news, using FinnHub.\n",
    "#### - Market Researcher - the specialist of finding financial hard data like market trends, stock prices, etc.\n",
    "#### - Writer - the specialist of taking all the information and preparing a polished answer for the user\n",
    "#### 5. Main Orchestrator Agent - this section contains the code in file /modules/agent.py and has the definition for the orchestrator agent, which develops the strategy and coordinates all subagents.\n",
    "#### 6. Main - this section contains the code in our main notebook, /main.ipynb - our implementation file where we execute all the above.\n",
    "### 1. TOOLS.\n",
    "#### One of the four agent functions we'll implement is the usage of tools, which will be defined in this first section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d5847078-4728-443e-9d7f-3a350066678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "#import modules.tools as tools\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import finnhub\n",
    "from typing import Callable\n",
    "from datetime import datetime, timedelta\n",
    "from google import genai\n",
    "import openai\n",
    "# For privacy reasons, we'll store our token keys on a .env file, which we'll load here:\n",
    "dotenv.load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "\n",
    "\n",
    "# First, we'll define a generic Tool class, which will serve as a structure for all of our tools\n",
    "class Tool:\n",
    "    def __init__(self, name, function, description, api=None): # This is the initialization method of the class\n",
    "        self.name = name # Placeholder for the name of the tool\n",
    "        self.function = function # Placeholder for the code of the tool's function\n",
    "        self.description = description # Placeholder for the description of the tool - very important since the agents will use this description to know what the tool does\n",
    "        self.api = api  # Placeholder for API details when needed\n",
    "        \n",
    "    def to_dict(self): # The structure of each class will always be a standard dictionary object that can be easily interpreted by the Agents\n",
    "        return {\n",
    "            \"name\": self.name,\n",
    "            \"description\": self.description,\n",
    "            \"api\": self.api\n",
    "        }\n",
    "    \n",
    "    def invoke(self, **kwargs): # This is the placeholder of the function for the tool, which will receive a variable number of parameters\n",
    "        print(f\"Invoking {self.name} with arguments {kwargs}\")\n",
    "        return self.function(**kwargs) # Returning the results of the function\n",
    "\n",
    "# Next, we'll declare each individual tool as a class, inheriting from the generic class Tool above\n",
    "class YahooFinance(Tool): # The first tool is YahooFinance, which will pull stock quotes for a given financial symbol, like AAPL for Apple\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"Yahoo Finance Stock Quote\", # Name of the tool\n",
    "            function=self.get_stock_quote_yahoo, # Pointing to the YahooFinance function below as this class's own function\n",
    "            description=\"Get the latest stock quote for a given symbol from Yahoo Finance.\", # Definition of the tool for our agents\n",
    "            api=\"\"\"{ \"\"symbol\": \"AAPL\"}\"\"\", # Parameter sample for the agent to use when it uses this class\n",
    "        )\n",
    "    def get_stock_quote_yahoo(self, symbol: str, step: str='') -> dict: # This is the function that pulls the stock using YahooFinance API\n",
    "        # Here we'll perform the call to YahooFinance to get the data from the specified symbol.\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        # Then, we'll use the 'fast_info' method, which pulls basic financial information, including the price.\n",
    "        try:\n",
    "            info = ticker.fast_info # Pulling the information and parsing it to return it\n",
    "            return {\n",
    "                \"symbol\": symbol,\n",
    "                \"last_price\": info[\"lastPrice\"],\n",
    "                \"day_high\": info[\"dayHigh\"],\n",
    "                \"day_low\": info[\"dayLow\"],\n",
    "                \"previous_close\": info[\"previousClose\"]\n",
    "            }\n",
    "        except Exception as e: # Should there be any errors, we will print the error message instead and return an empty dictionary\n",
    "            print(f\"Yahoo Finance API error: {e}\")\n",
    "            return {}\n",
    "#Now, we'll continue with the class that calls Financial Modeling Prep API\n",
    "class FMP(Tool):\n",
    "    def __init__(self,name:str,function:Callable=None,description:str=None,api:str=None,endPoint:str=None):\n",
    "        super().__init__(name=name,function=self.execute if function==None else function,description=description,api=api)\n",
    "        self.endpoint = endPoint if endPoint!=None else  os.getenv(\"FMP_Endpoint\") # It reads the endpoint from our .env file\n",
    "        self.apikey = os.getenv(\"FMP_API_KEY\") # It also reads the API key from our .env file\n",
    "    def execute(self, symbol: str) -> dict: # This is the function that pulls the stock data using FMP API\n",
    "        params = { #These are the parameters for the API call in a dictionary format\n",
    "            \"symbol\": symbol,\n",
    "            \"apikey\": self.apikey,\n",
    "            \"exchange\": \"NASDAQ\"\n",
    "        }\n",
    "        try: #Then we'll try to make the call to the API and return its formatted response as a JSON text\n",
    "            # print(f'Calling FMP API at endpoint: {self.endpoint} with params: {params}')\n",
    "            response=requests.get(self.endpoint, params=params)\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e: # Should there be any errors, we'll print the error message and return an empty dictionary\n",
    "            print(f'FMP API error: {e}')\n",
    "            return {}\n",
    "        \n",
    "class StockQuote(FMP):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"Stack Quote\", # Name of the tool\n",
    "            description=\"Get the latest stock quote for a given symbol from Stack Quote.\", # Definition of the tool for our agents\n",
    "            api=\"\"\"{ \"symbol\": \"AAPL\"}\"\"\", # Parameter sample for the agent to use when it uses this class\n",
    "            endPoint='https://financialmodelingprep.com/stable/quote' # It reads the endpoint from our .env file\n",
    "        )\n",
    "\n",
    "        \n",
    "class StockPriceChange(FMP):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"Stock Price Change\", # Name of the tool\n",
    "            description=\"Get the stock price change for a given symbol over the past.\", # Definition of the tool for our agents\n",
    "            api=\"\"\"{ \"symbol\": \"AAPL\", \"days\": 7}\"\"\", # Parameter sample for the agent to use when it uses this class\n",
    "            endPoint='https://financialmodelingprep.com/stable/stock-price-change' # It reads the endpoint from our .env file\n",
    "        )\n",
    "        \n",
    "class IncomeStatement(FMP):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"Income Statement\", # Name of the tool\n",
    "            description=\"Get the income statement for a given symbol from Financial Modeling Prep (FMP).\", # Definition of the tool for our agents\n",
    "            api=\"\"\"{ \"symbol\": \"AAPL\"}\"\"\", # Parameter sample for the agent to use when it uses this class\n",
    "            endPoint='https://financialmodelingprep.com/stable/income-statement' # It reads the endpoint from our .env file\n",
    "        )\n",
    "  \n",
    "class FinancialScore(FMP):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"Financial Score\", # Name of the tool\n",
    "            description=\"Get the financial score for a given symbol from Financial Modeling Prep (FMP).\", # Definition of the tool for our agents\n",
    "            api=\"\"\"{ \"symbol\": \"AAPL\"}\"\"\" ,# Parameter sample for the agent to use when it uses this class\n",
    "            endPoint='https://financialmodelingprep.com/stable/financial-scores' # It reads the endpoint from our .env file\n",
    "        )\n",
    "   \n",
    "        \n",
    "#We'll be using FinnHub as our News provider next\n",
    "class FinancialNews(Tool): \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"FinnHub News\", # Name of the tool\n",
    "            function=self.get_stock_quote_finnhub, # Pointing to the FinnHub function below as this class's own function\n",
    "            description=\"Get the latest financial news for a given symbol from FinnHub.\", # Definition of the tool for our agents\n",
    "            api=\"\"\"{ \"\"symbol\": \"AAPL\"}\"\"\" # Parameter sample for the agent to use when it uses this class\n",
    "        )\n",
    "    def get_stock_quote_finnhub(self, symbol: str, step: str='') -> dict: # This is the function that pulls the news data using FinnHub\n",
    "        FinnHubAPIKey = os.getenv(\"FINNHUB_API_KEY\") # Gets the API key from our .env file\n",
    "        # Next, we setup the client to perform calls:\n",
    "        finn_client = finnhub.Client(api_key=FinnHubAPIKey)\n",
    "\n",
    "        # Setting a time frame for the news, ending today and starting a week ago\n",
    "        end_date = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "        start_date = (datetime.today() - timedelta(days=7)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Now, we call the API, returning the news in the already pre-formatted dictionary structure.\n",
    "        try:\n",
    "            news= finn_client.company_news(symbol, _from=start_date, to=end_date)\n",
    "            if len(news)==0:\n",
    "                return {\"message\": f\"No news found for symbol {symbol} from {start_date} to {end_date}.\"}\n",
    "            top_news = sorted(news, key=lambda x: x['datetime'], reverse=True)[:5]\n",
    "            top_news_formatted = []\n",
    "            for item in top_news:\n",
    "                top_news_formatted.append({\n",
    "                    \"headline\": item.get(\"headline\"),\n",
    "                    \"summary\": item.get(\"summary\"),\n",
    "                    \"datetime\": datetime.fromtimestamp(item.get(\"datetime\")).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                })\n",
    "        \n",
    "            return {\n",
    "                \"symbol\": symbol,\n",
    "                \"news\": top_news_formatted  \n",
    "            }\n",
    "    \n",
    "        except Exception as e: # Should there be any errors, we'll print the error message and return an empty dictionary\n",
    "            print(f'Finnhub.io API error: {e}')\n",
    "            return {}\n",
    "\n",
    "class RecommendationTrends(Tool):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"FinnHub Recommendation Trends\", # Name of the tool\n",
    "            function=self.get_recommendation_trends, # Pointing to the FinnHub function below as this class's own function\n",
    "            description=\"Get the recommendation trends for a given symbol from FinnHub.\", # Definition of the tool for our agents\n",
    "            api=\"\"\"{ \"\"symbol\": \"AAPL\"}\"\"\" # Parameter sample for the agent to use when this class\n",
    "        )\n",
    "    def get_recommendation_trends(self, symbol: str) -> dict:\n",
    "        FinnHubAPIKey = os.getenv(\"FINNHUB_API_KEY\") # Gets the API key from our .env file\n",
    "        finn_client = finnhub.Client(api_key=FinnHubAPIKey)\n",
    "        try:\n",
    "            return finn_client.recommendation_trends(symbol)\n",
    "        except Exception as e: # Should there be any errors, we'll print the error message and return an empty dictionary\n",
    "            print(f'Finnhub.io API error: {e}')\n",
    "            return {}\n",
    "        \n",
    "class EarningSurprise(Tool):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"FinnHub Earning Surprise\", # Name of the tool\n",
    "            function=self.get_earning_surprise, # Pointing to the FinnHub function below as this class's own function\n",
    "            description=\"Get the earning surprise for a given symbol from FinnHub.\", # Definition of the tool for our agents\n",
    "            api=\"\"\"{ \"\"symbol\": \"AAPL\"}\"\"\" # Parameter sample for the agent to use when this class\n",
    "        )\n",
    "    def get_earning_surprise(self, symbol: str) -> dict:\n",
    "        FinnHubAPIKey = os.getenv(\"FINNHUB_API_KEY\") # Gets the API key from our .env file\n",
    "        finn_client = finnhub.Client(api_key=FinnHubAPIKey)\n",
    "        try:\n",
    "            return finn_client.company_earnings(symbol,limit=5)\n",
    "        except Exception as e: # Should there be any errors, we'll print the error message and return an empty dictionary\n",
    "            print(f'Finnhub.io API error: {e}')\n",
    "            return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3cc3d202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'symbol': 'AAPL', 'news': [{'headline': \"September Readers ID'd 17 Ideal 'Safer' Dividends In 39 Dogs\", 'summary': 'Discover the top ReFa/Ro dividend stocks for September 2025 with high yields and analyst-backed returns. Click for the picks.', 'datetime': '2025-10-17 10:54:16'}, {'headline': 'Apple Commits New Investments in Both China and the U.S.', 'summary': 'CEO Tim Cook balances expansion between two key markets amid global supply chain competition.', 'datetime': '2025-10-17 10:06:14'}, {'headline': 'Sell Tesla Stock, Analyst Says. Why Shares Are Rising.', 'summary': 'Sell Tesla Stock, Analyst Says. Why Shares Are Rising.', 'datetime': '2025-10-17 09:21:00'}, {'headline': 'Apple Secures Formula One’s U.S. Streaming Rights', 'summary': 'Apple  has signed a five-year deal with Formula One for the U.S. rights to air its races, broadening its menu of live sporting events it will offer on its streaming platform.  Apple TV will begin airing races in 2026.  F1 TV Premium, F1’s own streaming service, will be available to subscribers in the U.S. through Apple TV.', 'datetime': '2025-10-17 09:15:00'}, {'headline': 'Social TV Market Trends and Business Opportunities to 2030 Featuring Samsung, Apple, Ooyala (Dalet), Twitter, Facebook, Twitch, and YouTube', 'summary': 'The Social TV Market offers significant opportunities through technological enhancements, particularly with smart TVs, 5G, and second-screen devices enhancing interactive content. Growth is driven by smartphone and tablet penetration and social media integration with TV content, with Europe and North America leading the market.Dublin, Oct. 17, 2025 (GLOBE NEWSWIRE) -- The \"Social TV Market - Forecasts from 2025 to 2030\" has been added to ResearchAndMarkets.com\\'s offering. The Global Social TV Ma', 'datetime': '2025-10-17 09:10:00'}]}\n"
     ]
    }
   ],
   "source": [
    "news= FinancialNews().get_stock_quote_finnhub(symbol=\"AAPL\")\n",
    "print(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1156b878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadd7b2a-b7e4-45df-8551-153c0d0da84b",
   "metadata": {},
   "source": [
    "### 2. PARSER\n",
    "#### One of the workflow patterns our agents will do is routing, meaning our main agent will coordinate with subagents. To accomplish this communication, we need a \"common language\", which in this case will be JSON. This section defines the functions to implement the JSON parsing functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa5fdb39-7ca7-4dca-8fb9-6173fa06dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll define first a Parser abstract class\n",
    "class Parser:\n",
    "    def parse(self, response): # This is the placeholder of the default method for this class\n",
    "        # Here's the returned value, which will be a dictionary with an Action value, and a list of dynamic parameters.\n",
    "        return {\"action\": \"FinalAnswer\", \"parameters\": {}}\n",
    "# Next, we'll define an XML parser, which inherits from our abstract class Parser.    \n",
    "class XmlParser(Parser):\n",
    "    def parse(self, response):\n",
    "        # A parser that extracts XML tags from the response.\n",
    "        # For example, it looks for <InvokeTool>{\"symbol\": \"AAPL\", \"step\": \"financials\"}</InvokeTool>\n",
    "        # or <FinalAnswer>answer</FinalAnswer>.\n",
    "        # Returns : a dict with action and parameters. Example:\n",
    "        # {\n",
    "        #    \"action\": \"InvokeTool\",\n",
    "        #    \"parameters\": {\n",
    "        #        \"symbol\": \"AAPL\",\n",
    "        #        \"step\": \"financials\"\n",
    "        #    }\n",
    "        #}\n",
    "        import re\n",
    "        pattern = r'<(\\w+)>(.*?)</\\1>' # Defining the regular expression for XML structure\n",
    "        matches = re.findall(pattern, response) # Identifying all matches of XML\n",
    "        if matches: # When there are XML matches, we'll separate them and parse their contents\n",
    "            action, content = matches[0]\n",
    "            content = content.strip()\n",
    "            contentJson = {}\n",
    "            try:\n",
    "                import json\n",
    "                contentJson = json.loads(content) # Once parsed, we'll reformat them to JSON\n",
    "            except:\n",
    "                contentJson = {\"content\": content} # If the content is not valid, we'll return the error message with the invalid content text\n",
    "                return {\"action\": action, \"parameters\": contentJson, \"error\": \"Content is not valid JSON\"}\n",
    "            return {\"action\": action, \"parameters\": contentJson} # If it was valid, we return the parsed content in JSON format\n",
    "        return {\"action\": \"FinalAnswer\", \"parameters\": {}} #If there wasn't any XML to begin with, we just return an empty list of parameters\n",
    "    # Next, we have a specialized parsing for our agent's functionality that will interpret the actions in XML tags and encode them as a list of dictionaries\n",
    "    def  parse_all(self, response):\n",
    "        import re\n",
    "        pattern = r'<(\\w+)>(.*?)</\\1>' # Defining the regular expression for XML structure\n",
    "        matches = re.findall(pattern, response) # Identifying all matches of XML\n",
    "        results = [] # Preparing an empty array for the results\n",
    "        for action, content in matches: # For each detected action (if any),\n",
    "            content = content.strip()   # we'll parse its contents\n",
    "            contentJson = {}\n",
    "            try: # Then, we'll try to convert it to JSON format\n",
    "                import json\n",
    "                contentJson = json.loads(content)\n",
    "            except: # Should any errors occur, we'll return the error message as part of the response\n",
    "                contentJson = {\"content\": content}\n",
    "                results.append({\"action\": action, \"parameters\": contentJson, \"error\": \"Content is not valid JSON\"})\n",
    "                continue\n",
    "            results.append({\"action\": action, \"parameters\": contentJson}) # If everything's fine, we'll return the parsed JSON content\n",
    "        if not results:\n",
    "            results.append({\"action\": \"FinalAnswer\", \"parameters\": {}}) # If there were no actions, we'll return an empty dictionary\n",
    "        return results  \n",
    "    \n",
    "    def parseTags(self, response):\n",
    "        '''Agent response parser to extract all TAGS.\n",
    "            Returns a dictionary with tag names as keys and tag values as values.\n",
    "        '''\n",
    "        import re\n",
    "        pattern = r'<(\\w+)>(.*?)</\\1>'\n",
    "        matches = re.findall(pattern, response)\n",
    "        result = {}\n",
    "        for tag, value in matches:\n",
    "                result[tag.lower()] = value.strip() \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b0e958-92da-4165-acd4-d541e967c259",
   "metadata": {},
   "source": [
    "### 3. MEMORY.\n",
    "#### Another feature of our agent is learning, which means the agent must remember information as it gets prompted to refine their answers and keep getting more knowledgeable as it gets used. The functions that perform such learning are defined in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef5315f5-f806-4c34-87f7-f4187f6baa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "# We're creating a class called MemorySystem with all the learning functionality\n",
    "class MemorySystem:\n",
    "    # This class stores insights and lessons from previous analyses to improve future runs.\n",
    "    def __init__(self, memory_file='agent_memory.pkl'): # It will store the learned data into the specified file, or the default file name.\n",
    "        self.memory_file = memory_file\n",
    "        self.stock_insights = {}\n",
    "        self.news_insights = {}\n",
    "        self.load_memory()\n",
    "    \n",
    "    def load_memory(self): # Should there be a previous file in existence, it can load it using this function\n",
    "        try:\n",
    "            if os.path.exists(self.memory_file): # It will look for the file name specified in the instance of this class\n",
    "                with open(self.memory_file, 'rb') as f: # If it exists, it will attempt to open it\n",
    "                    memory_data = pickle.load(f) # Then, it will load the data into memory\n",
    "                    self.stock_insights = memory_data.get('stock_insights', {}) # separating stock insights,\n",
    "                    self.news_insights = memory_data.get('news_insights', {}) # market news insights,\n",
    "            else: # Should there be no prior file, it will start fresh\n",
    "                print(\"No memory file found. Starting with empty memory.\")\n",
    "        except Exception as e: # Should there be an error while loading the file, it will start fresh as well\n",
    "            print(f\"Error loading memory: {e}\")\n",
    "            print(\"Starting with empty memory.\")\n",
    "    \n",
    "    def save_memory(self): # This method will save the memory in the file in a structured manner\n",
    "        try:\n",
    "            memory_data = {\n",
    "                'stock_insights': self.stock_insights, # It will save all stock insights currently provided,\n",
    "                'news_insights': self.news_insights # followed by news insights\n",
    "            }\n",
    "            with open(self.memory_file, 'wb') as f: # It will first open the file name specified in the instance of this class\n",
    "                pickle.dump(memory_data, f) # and then write in it the contents of the memory_data dictionary\n",
    "            print(\"Memory saved successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving memory: {e}\") # Should there be any errors saving, it will print out the error\n",
    "    \n",
    "    def add_stock_insight(self, symbol, insight, timestamp=None): # With this method, we'll add knowledge classified as stock insights\n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now().isoformat() # If no timestamp is specified, we'll initialize the current time stamp\n",
    "        \n",
    "        if symbol not in self.stock_insights: # If the current symbol (financial company) is not in previous insights, we'll add it\n",
    "            self.stock_insights[symbol] = []\n",
    "        \n",
    "        self.stock_insights[symbol].append({ # Finally, we encode the insight with its timestamp in the stock_insights dictionary of this class\n",
    "            'insight': insight,\n",
    "            'timestamp': timestamp\n",
    "        })\n",
    "        self.save_memory() # And we save the memory right away\n",
    "    \n",
    "    def add_market_news(self,symbol, news_item, timestamp=None): # This method adds market news insights for a given symbol\n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now().isoformat() # If no timestamp is specified, we'll initialize the current time stamp\n",
    "\n",
    "        if symbol not in self.news_insights: # If the current symbol (financial company) is not in previous insights, we'll add it\n",
    "            self.news_insights[symbol] = []\n",
    "\n",
    "        self.news_insights[symbol].append({ # Finally, we encode the news item with its timestamp in the news_insights dictionary of this class\n",
    "            'news_item': news_item,\n",
    "            'timestamp': timestamp\n",
    "        })\n",
    "        self.save_memory() # And we save the memory right away\n",
    "\n",
    "    def get_stock_insights(self, symbol): # This method retrieves all stock insights for a given symbol\n",
    "        results=self.stock_insights.get(symbol, [])\n",
    "        if not results:\n",
    "            print(f\"No insights found for symbol {symbol}.\")\n",
    "            return []\n",
    "        if results:\n",
    "            filtered_results = []\n",
    "            for result in results:\n",
    "                # if the timestamp is older than 7 days, we can choose to ignore it\n",
    "                timestamp = datetime.fromisoformat(result['timestamp'])\n",
    "                if (datetime.now() - timestamp).days > 7:\n",
    "                    continue\n",
    "                filtered_results.append(result)\n",
    "        return filtered_results\n",
    "\n",
    "    def get_news_insights(self, symbol): # This method retrieves all market news insights for a given symbol\n",
    "        results=self.news_insights.get(symbol, [])\n",
    "        if not results:\n",
    "            print(f\"No news insights found for symbol {symbol}.\")\n",
    "            return []\n",
    "        if results:\n",
    "            filtered_results = []\n",
    "            for result in results:\n",
    "                # if the timestamp is older than 2 days, we can choose to ignore it\n",
    "                timestamp = datetime.fromisoformat(result['timestamp'])\n",
    "                if (datetime.now() - timestamp).days > 2:\n",
    "                    continue\n",
    "                filtered_results.append(result)\n",
    "        return filtered_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf287589-30f8-4c56-a61c-175eeaf9af11",
   "metadata": {},
   "source": [
    "### 4. AGENTS\n",
    "#### For our routing workflow, along with communication also comes specialization and tool usage: a team of agents that will collaborate, coordinated by the main orchestrator agent. That's what we'll define in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13a923fc-91cd-40c0-aeb6-55eb20d0bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we'll initialize the Google GenAI and OpenAI\n",
    "from google import genai\n",
    "import openai\n",
    "#Make sure to load the environmental variables\n",
    "dotenv.load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "\n",
    "# Downloading necessary libraries and functionality - uncomment when needed.\n",
    "#nltk.download('vader_lexicon')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "class Agent: # This will be our base class for all our agents\n",
    "    def __init__(self, name, role, system_prompt, model, generate_response, agents=None, tools=None, memory_system=None, parser=None): # This is the initialization method of the Agent class\n",
    "        self.name = name # Placeholder for the name of the tool\n",
    "        self.model = model # Placeholder for the LLM model\n",
    "        self.role = role # Placeholder for the role of this agent\n",
    "        self.system_prompt = system_prompt # Placeholder for the system prompt that defines this agent\n",
    "        self.memory_system = memory_system # Placeholder for the memory object for this agent - it could be None, so the agent would start without knowledge\n",
    "        self.parser = parser  # Placeholder for API details when needed\n",
    "        self.generate_response = generate_response # Placeholder for the generate response method\n",
    "        self.agents = agents \n",
    "        self.tools = tools # Placeholder for the tools passed on to this agent, which should be a list\n",
    "        self.conversation_history = [] # Initializing a blank conversation history\n",
    "        self.max_history_length = 10 # Initializing a default max number of history length\n",
    "\n",
    "        self.prompt_template = (\n",
    "            \"You are {agent_name}, an AI agent. Use the following tools as needed:\\n\"\n",
    "            \"{tools}\\n\"\n",
    "            \"Conversation history:\\n\"\n",
    "            \"{history}\\n\"\n",
    "            \"Current input: {input}\\n\"\n",
    "            \"Respond appropriately.\"\n",
    "        )\n",
    "        self.initialize_client()\n",
    "    #We want our Agent class to support multiple LLMs, so this function will help initialize its internal client dynamically.\n",
    "    def initialize_client(self):\n",
    "        #For GPT models\n",
    "        if \"gpt\" in self.model.lower(): \n",
    "            self.client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        #For Gemini models\n",
    "        elif \"gemini\" in self.model.lower():\n",
    "            self.client = genai.Client()\n",
    "    def to_dict(self): # The structure of each class will always be a standard dictionary object that can be easily interpreted by the Agents\n",
    "        return {\n",
    "            \"name\": self.name,\n",
    "            \"description\": self.description,\n",
    "            \"api\": self.api\n",
    "        }\n",
    "    def register_tool(self, tool):\n",
    "        self.tools.append(tool)\n",
    "    def remember(self, message):\n",
    "        self.conversation_history.append(message)\n",
    "        if len(self.conversation_history) > self.max_history_length:\n",
    "            self.conversation_history.pop(0)\n",
    "    def call_llm(self, input_prompt):\n",
    "        try:\n",
    "            #For GPT models\n",
    "            if \"gpt\" in self.model.lower(): \n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": input_prompt}\n",
    "                    ],\n",
    "                    max_tokens=300,\n",
    "                    temperature=0.7\n",
    "                )\n",
    "                result = response.choices[0].message.content\n",
    "            #For Gemini models\n",
    "            elif \"gemini\" in self.model.lower():\n",
    "                prompt = self.system_prompt\n",
    "                prompt += \"\\n Orchestrator:\" + input_prompt\n",
    "                response = self.client.models.generate_content(\n",
    "                    model=self.model, contents=prompt\n",
    "                )\n",
    "                result = response.text\n",
    "            #print(f\"{self.name} using model '{self.model}': {result[:60]}...\")\n",
    "            #print(result)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\" API failed for {self.name} using model '{self.model}': {e}\")\n",
    "            return f\"Mock response from {self.name} with model '{self.model}': {input_prompt[:50]}...\"\n",
    "    def generate_response(self, **kwargs): # This is the placeholder of the generative function for the agent, which will receive a variable number of parameters\n",
    "        print(f\"Invoking {self.name} generative response function with arguments {kwargs}\")\n",
    "        return self.generate_response(**kwargs) # Returning the results of the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed17b1-9690-4054-8131-025b22fe39fb",
   "metadata": {},
   "source": [
    "#### Next, let's define some Sub-agents that will inherit from the class above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ac90380-12c0-4734-8642-c0c0445c230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Writer(Agent):\n",
    "    # This agent takes the results of other agents (like news or market research) and creates a professional report that will be returned to the Orchestrator for the Final Response to the user.\n",
    "    def __init__ (self, model=\"gpt-3.5-turbo\", agents=None, memory_system=None):\n",
    "        super().__init__(\n",
    "            name=\"Writer\", #Name of the Writer class\n",
    "            role=\"financial content writer\", #Role of this class\n",
    "            system_prompt=(\n",
    "                \"You are Writer, an AI agent part of an agents team. Your role is a professional \"\n",
    "                \"financial report writer, capable of taking financial news \"\n",
    "                \"or financial information provided by the Orchestrator and \"\n",
    "                \"preparing a 2–3 paragraph report that provides a clear final \"\n",
    "                \"answer to the user.\"\n",
    "                \"Here are some guidelines for you:\"\n",
    "                \"Start your answers giving a positive message like 'Excellent question', 'Great question', or similar.\"\n",
    "                \"Focus on answering the user's question.\"\n",
    "                \"When recommendations are requested, only provide guidance and highlight pros and cons.\"\n",
    "                \"The news or financial information you're receiving came from other agents in the team, so never refer to it as 'the data provided'.\"\n",
    "            ),            \n",
    "            model = model,\n",
    "            generate_response = self.generate_response,\n",
    "            memory_system = memory_system\n",
    "        )\n",
    "    def generate_response(self, input_prompt):\n",
    "        result = self.call_llm(input_prompt)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9131fe8-cb38-4132-a7a7-76aae303751b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Excellent question! Evaluating whether it's a good time to buy a stock like Apple involves weighing multiple factors, including recent developments and market sentiment.\\n\\nApple is showing strong engagement in the burgeoning field of Artificial Intelligence, with plans for smart glasses and integrating AI capabilities across its product lines, which could be a significant long-term growth driver. Furthermore, demand for the upcoming iPhone 17 is reportedly robust. The stock has also seen a modest positive movement over the past two days, rising from $254.04 to $255.74, indicating some positive short-term momentum. These aspects suggest a company actively innovating and maintaining strong consumer interest in its core products.\\n\\nHowever, potential investors should also consider some cautionary points. While current iPhone demand is strong, some analysts express caution regarding expectations for future models. Additionally, Apple is currently facing legal scrutiny concerning chip royalties and data collection practices. Such legal challenges can introduce uncertainty and potential financial implications, which could weigh on the stock's performance. Therefore, while the company's innovation in AI and current product demand are attractive, the ongoing legal issues and long-term analyst expectations warrant careful monitoring.\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can use \"gpt-3.5-turbo\" or \"gemini-2.5-flash\", #Uncomment if using Google GenAI\n",
    "MyWriter = Writer(model=\"gemini-2.5-flash\")\n",
    "\n",
    "sample_prompt = (\"Orchestrator: The user wants to know if, based on the latest news and stock prices it is a good time to buy Apple stock. \"\n",
    "                    \"Here are the latest news: Apple is deeply involved in AI, planning smart glasses and integrating AI into its products. The iPhone 17 is seeing strong demand, though some analysts are cautious about future models' expectations. Apple faces legal scrutiny regarding chip royalties and data collection.\"\n",
    "                    \"Here are stock prices for the past 2 days: The stock price on 10/17/2025 was **$254.04**. The stock price on 10/18/2025 is **$255.74**\"\n",
    "                )\n",
    "\n",
    "MyWriter.generate_response(sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "94b97db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketResearchAgent(Agent):\n",
    "    def __init__(self,model=\"gemini-2.5-flash\"):\n",
    "        name=\"Market Research Agent\"\n",
    "        model=model\n",
    "        role=\"Market Research Agent specialized in financial data analysis and market trends\"\n",
    "        system_prompt=f\"\"\"You are a Market Research Agent specialized in financial data analysis and market trends.\n",
    "         Your role is to assist users by providing accurate and up-to-date financial information, stock quotes, market trends, and insights based on the latest data available from various financial APIs and tools.\n",
    "\n",
    "         Based on the data retrieved from the tools at your disposal, provide comprehensive answers to user queries related to stock performance, market analysis, and financial news.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.memory_system=MemorySystem()\n",
    "        super().__init__(name=name,system_prompt=system_prompt,model=model,generate_response=self.generate_response,role=role,agents=None,tools=None,memory_system=self.memory_system,parser=None) \n",
    "    \n",
    "    def generate_response(self, **kwargs): # This is the placeholder of the generative function for the agent, which will receive a variable number of parameters\n",
    "        # print(f\"Invoking {self.name} generative response function with arguments {kwargs}\")\n",
    "        input_prompt=kwargs.get(\"prompt\",[])\n",
    "        try:\n",
    "            #For GPT models\n",
    "            if \"gpt\" in self.model.lower(): \n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=input_prompt,\n",
    "                    max_tokens=300,\n",
    "                    temperature=0.7\n",
    "                )\n",
    "                result = response.choices[0].message.content\n",
    "            #For Gemini models\n",
    "            elif \"gemini\" in self.model.lower():\n",
    "                response = self.client.models.generate_content(\n",
    "                    model=self.model, contents=str(input_prompt)\n",
    "                )\n",
    "                result = response.text\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\" API failed for {self.name} using model '{self.model}': {e}\")\n",
    "            return f\"Mock response from {self.name} with model '{self.model}': {input_prompt[:50]}...\"\n",
    "\n",
    "    def getMarketSummary(self,symbol:str  ) -> str:\n",
    "        prompt=f\"\"\"Provide a comprehensive market summary for the stock symbol: {symbol}. \n",
    "                Include recent performance, key financial metrics, and any notable news or trends affecting the stock.\n",
    "                Use data from Yahoo Finance, Financial Modeling Prep, and FinnHub to inform your summary.\n",
    "                Format the response in a clear and concise manner suitable for a financial report.\"\"\"\n",
    "        insights = self.memory_system.get_stock_insights(symbol)\n",
    "        if insights:\n",
    "            print(f\"Using cached insight for symbol {symbol}.\")\n",
    "            return insights[-1]['insight']\n",
    "        else:\n",
    "            tools_list=[FinancialScore(),IncomeStatement(),StockQuote(),StockPriceChange()]\n",
    "            for tool in tools_list:\n",
    "                tool_response=tool.invoke(symbol=symbol)\n",
    "                prompt+=f\"\\nData from {tool.name}: {tool_response}\"\n",
    "            response=self.generate_response(prompt=prompt)\n",
    "            self.memory_system.add_stock_insight(symbol, response,timestamp=datetime.now().isoformat())\n",
    "        return response  \n",
    "    \n",
    "    def  processUserInput(self, user_input: str) -> str:\n",
    "        tags=self.getEntities(user_input=user_input)\n",
    "        if \"symbol\" in tags:\n",
    "            marketSummary=self.getMarketSummary(symbol=tags.get(\"symbol\"))\n",
    "        prompt=f\"\"\"Based on the {marketSummary} Analyze the following user input\n",
    "                and provide a short answer for the user query.\n",
    "                Rules:\n",
    "                - If the user input is related to stock performance, provide insights based on the market summary.\n",
    "                - If the user input is unrelated to financial markets, respond with \"I'm sorry, I can only assist with financial market-related queries.\"\n",
    "                - Keep the response concise and relevant to the user's query.\n",
    "                - Use a professional and informative tone suitable for financial discussions.\n",
    "                - Limit the response to 150 words.\n",
    "\n",
    "                User Input: \"{user_input}\"\n",
    "\n",
    "\n",
    "                Answer:\n",
    "                \"\"\",\n",
    "        response=self.generate_response(prompt=prompt)\n",
    "        return response\n",
    "\n",
    "    def getEntities(self, user_input: str) -> str:\n",
    "        prompt=f\"\"\"Determine entities the following user input related to financial markets and stock analysis:\n",
    "                if the input contains Apple Inc, return SYMBOL as AAPL\n",
    "                if the input contains Microsoft Corporation, return SYMBOL as MSFT\n",
    "                User Input: \"{user_input}\n",
    "                Extracted Entities:\n",
    "                    <SYMBOL>...</SYMBOL>\n",
    "                    <EXCHANGE>...</EXCHANGE><INDUSTRY>...</INDUSTRY>  \"\"\"\n",
    "        response=self.generate_response(prompt=prompt)\n",
    "        parser=XmlParser()\n",
    "        parsed_response=parser.parseTags(response)\n",
    "        return parsed_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eb24a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketSentimentAgent(Agent):\n",
    "    def __init__(self,model=\"gemini-2.5-flash\"):\n",
    "        name=\"Market Sentiment Agent\"\n",
    "        model=model\n",
    "        role=\"Market Sentiment Agent specialized in financial news sentiment analysis\"\n",
    "        system_prompt=f\"\"\"You are a Market Sentiment Agent specialized in financial news sentiment analysis.\n",
    "         Your role is to assist users by analyzing the sentiment of financial news articles and providing insights based on the emotional tone of the content.\n",
    "\n",
    "         Based on the news data retrieved from FinnHub, provide comprehensive sentiment analysis to help users understand market mood and potential impacts on stock performance.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.memory_system=MemorySystem()\n",
    "        super().__init__(name=name,system_prompt=system_prompt,model=model,generate_response=self.generate_response,role=role,agents=None,tools=None,memory_system=self.memory_system,parser=None)\n",
    "        \n",
    "    def generate_response(self, **kwargs): # This is the placeholder of the generative function for the agent, which will receive a variable number of parameters\n",
    "        # print(f\"Invoking {self.name} generative response function with arguments {kwargs}\")\n",
    "        input_prompt=kwargs.get(\"prompt\",[])\n",
    "        try:\n",
    "            #For GPT models\n",
    "            if \"gpt\" in self.model.lower(): \n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=input_prompt,\n",
    "                    max_tokens=300,\n",
    "                    temperature=0.7\n",
    "                )\n",
    "                result = response.choices[0].message.content\n",
    "            #For Gemini models\n",
    "            elif \"gemini\" in self.model.lower():\n",
    "                response = self.client.models.generate_content(\n",
    "                    model=self.model, contents=str(input_prompt)\n",
    "                )\n",
    "                result = response.text\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\" API failed for {self.name} using model '{self.model}': {e}\")\n",
    "            return f\"Mock response from {self.name} with model '{self.model}': {input_prompt[:50]}...\"\n",
    "        \n",
    "    def getNewsSummary(self,symbol:str  ) -> str:\n",
    "            prompt=f\"\"\"Provide a comprehensive news summary for the stock symbol: {symbol}.\n",
    "                    Include recent news articles, key events, and any notable trends affecting the stock.\n",
    "                    Use data from FinnHub and other news sources to inform your summary.\n",
    "                    Format the response in a clear and concise manner suitable for a financial report.\"\"\"\n",
    "            insights = self.memory_system.get_news_insights(symbol)\n",
    "            if insights:\n",
    "                print(f\"Using cached insight for symbol {symbol}.\")\n",
    "                return insights[-1]['insight']\n",
    "            else:\n",
    "                tools_list=[FinancialNews(),RecommendationTrends(),EarningSurprise()]\n",
    "                for tool in tools_list:\n",
    "                    tool_response=tool.invoke(symbol=symbol)\n",
    "                    prompt+=f\"\\nData from {tool.name}: {tool_response}\"\n",
    "                response=self.generate_response(prompt=prompt)\n",
    "                self.memory_system.add_market_news(symbol, response,timestamp=datetime.now().isoformat())\n",
    "            return response\n",
    "        \n",
    "    def  processUserInput(self, user_input: str) -> str:\n",
    "        tags=self.getEntities(user_input=user_input)\n",
    "        if \"symbol\" in tags:\n",
    "            newsSummary=self.getNewsSummary(symbol=tags.get(\"symbol\"))\n",
    "        prompt=f\"\"\"Based on the {newsSummary} Analyze the following user input\n",
    "                and provide a short answer for the user query.\n",
    "                Rules:\n",
    "                - If the user input is related to financial news sentiment, provide insights based on the news summary.\n",
    "                - If the user input is unrelated to financial markets, respond with \"I'm sorry, I can only assist with financial market-related queries.\"\n",
    "                - Keep the response concise and relevant to the user's query.\n",
    "                - Use a professional and informative tone suitable for financial discussions.\n",
    "                - Limit the response to 150 words.\n",
    "\n",
    "                User Input: \"{user_input}\"\n",
    "\n",
    "\n",
    "                Answer:\n",
    "                \"\"\",\n",
    "        response=self.generate_response(prompt=prompt)\n",
    "        return response\n",
    "    def getEntities(self, user_input: str) -> str:\n",
    "        prompt=f\"\"\"Determine entities the following user input related to financial markets and stock analysis:\n",
    "                if the input contains Apple Inc, return SYMBOL as AAPL\n",
    "                if the input contains Microsoft Corporation, return SYMBOL as MSFT\n",
    "                User Input: \"{user_input}\n",
    "                Extracted Entities:\n",
    "                    <SYMBOL>...</SYMBOL>\n",
    "                    <EXCHANGE>...</EXCHANGE><INDUSTRY>...</INDUSTRY>  \"\"\"\n",
    "        response=self.generate_response(prompt=prompt)\n",
    "        parser=XmlParser()\n",
    "        parsed_response=parser.parseTags(response)\n",
    "        return parsed_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "abafc88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No news insights found for symbol TSLA.\n",
      "Invoking FinnHub News with arguments {'symbol': 'TSLA'}\n",
      "Invoking FinnHub Recommendation Trends with arguments {'symbol': 'TSLA'}\n",
      "Invoking FinnHub Earning Surprise with arguments {'symbol': 'TSLA'}\n",
      "Memory saved successfully.\n",
      "Based on the latest news, sentiment around Tesla (TSLA) stock is mixed but increasingly cautious. While a majority of analysts maintain \"Buy\" ratings, the stock is at a \"make-or-break point\" ahead of its Q3 2025 earnings. Concerns are rising due to a \"significant front-loading effect\" in Q3, a recent analyst downgrade, and three consecutive earnings misses. High EV costs and broader market volatility further contribute to uncertainty. A substantial portion of analysts hold a \"Hold\" recommendation, indicating a wait-and-see approach. Investors are keenly awaiting the Q3 earnings report to assess if Tesla can reverse recent negative trends.\n"
     ]
    }
   ],
   "source": [
    "newsAgent=MarketSentimentAgent(model=\"gemini-2.5-flash\")\n",
    "response=newsAgent.processUserInput(\"What is the sentiment around Tesla's stock based on the latest news?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4862007d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached insight for symbol TSLA.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current price for TSLA is $439.31. The stock is trading above its 50-day moving average of $387.45 and 200-day moving average of $334.72, within a 52-week range of $212.11 to $488.54. Tesla currently holds a high P/E ratio of 215.35x, reflecting a premium valuation based on high future growth expectations.\\n\\nDetermining the \"best\" buying price depends on individual investment strategy and market outlook, considering factors like current performance, valuation, and margin trends. This summary provides key metrics for your analysis.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marketAgent = MarketResearchAgent()\n",
    "marketAgent.processUserInput(\"What is the best price to buy Tesla stock right now?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7fae3d-16cf-4e77-9fd0-40f33e0ad6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = systemPrompt\n",
    "userText =\"\"\n",
    "continueFlag = False\n",
    "exitFlag = \"\"\n",
    "debug = False\n",
    "while userText.lower() != \"exit\" or exitFlag.lower() != \"y\":\n",
    "    if not continueFlag:\n",
    "        userText = input(\"User: \")\n",
    "        if userText.lower() == \"exit\":\n",
    "            break\n",
    "        prompt += \"\\n User:\"+ userText\n",
    "        continueFlag = False\n",
    "    if debug:\n",
    "        print('Prompt: ')\n",
    "        print(prompt)\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\", contents=prompt\n",
    "    )\n",
    "    if debug:\n",
    "        print('Model response: ')\n",
    "        print(response.text)\n",
    "    prompt = prompt + response.text\n",
    "    actions = parser.parse_all(response.text.replace('\\n', ' '))\n",
    "    if debug:\n",
    "        print('Actions: ')\n",
    "        print(actions)\n",
    "    if not actions:\n",
    "        continue\n",
    "    if len(actions) >= 1:\n",
    "        actions = { action['action']: action for action in actions if action.get(\"action\",\"\") != \"Final Answer\" }\n",
    "        if \"NeedApproval\" in actions:\n",
    "            actions.pop(\"NeedApproval\")\n",
    "            if \"InvokeTool\" in actions:\n",
    "                #result=input(\"Need to Call \" + actions[\"InvokeTool\"].get(\"name\",\"\") + \" Y/y to continue...)\")\n",
    "                result=input(\"Need to Call \" + actions[\"InvokeTool\"]['parameters']['name'] + \". Type Y/y to continue...)\")\n",
    "            else:\n",
    "                result=input(\"Need User Approval Y/y to continue...)\")\n",
    "            if result.lower() != \"y\":\n",
    "                print(\"Exiting...\")\n",
    "                break\n",
    "            actions[\"NeedApproval\"] = {\"action\":\"NeedApproval\", \"content\":\"User approved to continue.\"}\n",
    "            prompt += \"\\n User:\"+ actions[\"NeedApproval\"].get(\"content\",\"\")\n",
    "        if 'InvokeTool' in actions:\n",
    "            action = actions[\"InvokeTool\"]\n",
    "            tools_name = action[\"parameters\"][\"name\"]\n",
    "            tool_params = action[\"parameters\"][\"api\"]\n",
    "            result = executionMap[tools_name].invoke(**json.loads(tool_params))\n",
    "            actions[\"Tool result\"] = {\"action\":\"Tool result\", \"content\":result}\n",
    "            prompt += \"\\n User:\"+ str(result)\n",
    "            continueFlag = True\n",
    "        if \"FinalAnswer\" in actions:\n",
    "            content = actions[\"FinalAnswer\"]['parameters']['content']\n",
    "            print(\"Final Answer: \"+ str(content))\n",
    "            exitFlag = input(\"Do you want to exit? Type Y/y to exit...\")\n",
    "            if exitFlag.lower() == \"y\":\n",
    "                print('Thanks for chatting! Goodbye!')\n",
    "                break\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d208600-b43d-424f-b54d-7ee6f97c1257",
   "metadata": {},
   "source": [
    "### 5. MAIN ORCHESTRATOR AGENT.\n",
    "#### This is the section where we define the orchestrator agent, which performs the interpretation of the user's prompt, prepares a plan, calls the subagents as needed, and prepares the final answer to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa6bcc-d542-4354-80bc-95ad0e9cf6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrchestratorAgent(Agent):\n",
    "    def __init__(self, name, model, memory, parser=None):\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.memory = memory\n",
    "        self.conversation_history = []\n",
    "        self.tools = []\n",
    "        self.max_history_length = 10 \n",
    "        self.parser = parser\n",
    "        # Limit for conversation history\n",
    "        '''\n",
    "        You are a helpful Finance assistant that explains things in a few words.\n",
    "          You have the following tools:\n",
    "            {tools}\n",
    "        \n",
    "            ### Instructions for using the tools:\n",
    "            You should only use the tools listed above.\n",
    "            When you use a tool, you must call the API exactly as shown above.\n",
    "            You must always include the symbol in the API call.\n",
    "            You must always include the step in the API call.\n",
    "            You must always use double quotes for the JSON keys and string values in the API call.\n",
    "            You must never use single quotes in the API call.\n",
    "            You must never call any API that is not listed above.\n",
    "            You must never make up any API calls.\n",
    "            You must never repeat any steps.\n",
    "            \n",
    "            Here is an example of how to use the tools:\n",
    "            User : What is the company overview for \"AAPL\".\n",
    "            Assistant : To gather the company overview, I will use the \"Company Overview\" tool.\n",
    "            Assistant : <InvokeTool>{\"symbol\": \"AAPL\", \"step\": \"info\"}</InvokeTool>\n",
    "            Tool : <ToolResult>{\"name\": \"Company Overview\", \"result\": {\"companyName\": \"Apple Inc.\", \"sector\": \"Technology\", \"industry\": \"Consumer Electronics\"}}</ToolResult>\n",
    "            Assistant : <Thought>Based on the company overview, Apple Inc. is a leading technology company in the consumer electronics industry.</Thought>\n",
    "            \n",
    "            ### TAGs for tool usage:\n",
    "            - To use a tool, you must wrap the API call in <InvokeTool> and </InvokeTool> tags.\n",
    "            -  For thinking, you must wrap your thoughts in <Thought> and </Thought> tags.\n",
    "            -  For final answers, you must wrap your answer in <FinalAnswer> and </FinalAnswer> tags.\n",
    "            -  If you need users to provide more information, you must wrap your request in <RequestMoreInfo> and </RequestMoreInfo> tags.\n",
    "            -  If you are going to use a tool, you must always think first. Get the concern of the user query with <NeedApproval>, decide which tool to use, and then use the tool.\n",
    "           \n",
    "            ### Thinking Process: \n",
    "              Based on the user query, decide which tools to use and in what order.\n",
    "              After using a tool, analyze the result and decide the next step.\n",
    "              Continue this process until you have enough information to answer the user's query.\n",
    "              Finally, provide a comprehensive answer to the user's query.\n",
    "        '''\n",
    "        self.prompt_template = (\n",
    "            \"You are {agent_name}, an AI agent. Use the following tools as needed:\\n\"\n",
    "            \"{tools}\\n\"\n",
    "            \"Conversation history:\\n\"\n",
    "            \"{history}\\n\"\n",
    "            \"Current input: {input}\\n\"\n",
    "            \"Respond appropriately.\"\n",
    "        )\n",
    "\n",
    "    def register_tool(self, tool):\n",
    "        self.tools.append(tool)\n",
    "        \n",
    "    def remember(self, message):\n",
    "        self.conversation_history.append(message)\n",
    "        if len(self.conversation_history) > self.max_history_length:\n",
    "            self.conversation_history.pop(0)\n",
    "    \n",
    "    def generate_response(self, user_input):\n",
    "        tools_description = \"\\n\".join([f\"- {tool['name']}: {tool['description']}\" for tool in self.tools])\n",
    "        history_text = \"\\n\".join(self.conversation_history)\n",
    "        \n",
    "        prompt = self.prompt_template.format(\n",
    "            agent_name=self.name,\n",
    "            tools=tools_description,\n",
    "            history=history_text,\n",
    "            input=user_input\n",
    "        )\n",
    "        \n",
    "        response = self.model.generate_text(prompt)\n",
    "        self.remember(f\"User: {user_input}\")\n",
    "        self.remember(f\"{self.name}: {response}\")\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def reAct(self, user_input):\n",
    "        # Here you would implement the logic to parse the response for tool usage\n",
    "        # and handle the tool invocation and results.\n",
    "        if self.parser and self.tools:\n",
    "            # Execute generate response in a loop until a final answer is reached\n",
    "            response = self.generate_response(user_input)\n",
    "            parsed_response = self.parser.parse(response) ## parsed response is a dict {\"InvokeTool\": \"tool_name\", \"parameters\": {...}} or {\"FinalAnswer\": \"answer\"} or {\"RequestMoreInfo\": \"info\"}\n",
    "            system_message = f\"System: {response}\"\n",
    "            self.remember(system_message)\n",
    "            self.conversation_history.append(system_message)\n",
    "             '''\n",
    "                    parsed_response= {\n",
    "            \"action\": \"InvokeTool\",\n",
    "            \"parameters\": {\n",
    "                \"symbol\": \"AAPL\",\n",
    "                \"step\": \"financials\"\n",
    "            }\n",
    "        }\n",
    "                    '''\n",
    "            action = parsed_response.get(\"action\")\n",
    "            if action == \"InvokeTool\":\n",
    "                tool_name = parsed_response[\"parameters\"].get(\"tool_name\")\n",
    "                tool = next((t for t in self.tools if t['name'] == tool_name), None)\n",
    "                if tool:\n",
    "                    tool_result = tool['function'](**parsed_response.get(\"parameters\", {}))\n",
    "                    self.remember(f\"Tool Result: {tool_result}\")\n",
    "                    self.conversation_history.append(f\"Tool Result: {tool_result}\") \n",
    "                    # Generate a new response based on the tool result\n",
    "                    response = self.generate_response(f\"Tool Result: {tool_result}\")\n",
    "                    parsed_response = self.parser.parse(response)\n",
    "            elif action == \"FinalAnswer\" or action == \"RequestMoreInfo\" or action == \"NeedApproval\":\n",
    "                return parsed_response.get(\"content\")\n",
    "            else:\n",
    "                return \"I'm not sure how to proceed. Could you please clarify?\"\n",
    "            # Handle tool invocation and results based on parsed_response\n",
    "            # This is a placeholder for actual implementation\n",
    "            print(f\"Parsed Response: {parsed_response}\")\n",
    "\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abea2e1e-d811-44cb-83eb-1afd0d66f720",
   "metadata": {},
   "source": [
    "### 6. MAIN.\n",
    "#### This is the final section, which contains the implementation of the entire system using all elements above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6e69f-4a54-4dc9-ade0-1c38031f6ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_tools = [tools.YahooFinance(), tools.FMP(), tools.FinnHub()]\n",
    "toolsList = [ tool.to_dict() for tool in registered_tools ]\n",
    "executionMap= { tool.name: tool for tool in registered_tools }\n",
    "\n",
    "executionMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfbc0c6-0f5d-477f-9e3e-925cef221d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.parser as parser\n",
    "parser = parser.XmlParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a4fff4-e92e-4b1f-a976-497ffa407111",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = systemPrompt\n",
    "userText =\"\"\n",
    "continueFlag = False\n",
    "exitFlag = \"\"\n",
    "debug = False\n",
    "while userText.lower() != \"exit\" or exitFlag.lower() != \"y\":\n",
    "    if not continueFlag:\n",
    "        userText = input(\"User: \")\n",
    "        if userText.lower() == \"exit\":\n",
    "            break\n",
    "        prompt += \"\\n User:\"+ userText\n",
    "        continueFlag = False\n",
    "    if debug:\n",
    "        print('Prompt: ')\n",
    "        print(prompt)\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\", contents=prompt\n",
    "    )\n",
    "    if debug:\n",
    "        print('Model response: ')\n",
    "        print(response.text)\n",
    "    prompt = prompt + response.text\n",
    "    actions = parser.parse_all(response.text.replace('\\n', ' '))\n",
    "    if debug:\n",
    "        print('Actions: ')\n",
    "        print(actions)\n",
    "    if not actions:\n",
    "        continue\n",
    "    if len(actions) >= 1:\n",
    "        actions = { action['action']: action for action in actions if action.get(\"action\",\"\") != \"Final Answer\" }\n",
    "        if \"NeedApproval\" in actions:\n",
    "            actions.pop(\"NeedApproval\")\n",
    "            if \"InvokeTool\" in actions:\n",
    "                #result=input(\"Need to Call \" + actions[\"InvokeTool\"].get(\"name\",\"\") + \" Y/y to continue...)\")\n",
    "                result=input(\"Need to Call \" + actions[\"InvokeTool\"]['parameters']['name'] + \". Type Y/y to continue...)\")\n",
    "            else:\n",
    "                result=input(\"Need User Approval Y/y to continue...)\")\n",
    "            if result.lower() != \"y\":\n",
    "                print(\"Exiting...\")\n",
    "                break\n",
    "            actions[\"NeedApproval\"] = {\"action\":\"NeedApproval\", \"content\":\"User approved to continue.\"}\n",
    "            prompt += \"\\n User:\"+ actions[\"NeedApproval\"].get(\"content\",\"\")\n",
    "        if 'InvokeTool' in actions:\n",
    "            action = actions[\"InvokeTool\"]\n",
    "            tools_name = action[\"parameters\"][\"name\"]\n",
    "            tool_params = action[\"parameters\"][\"api\"]\n",
    "            result = executionMap[tools_name].invoke(**json.loads(tool_params))\n",
    "            actions[\"Tool result\"] = {\"action\":\"Tool result\", \"content\":result}\n",
    "            prompt += \"\\n User:\"+ str(result)\n",
    "            continueFlag = True\n",
    "        if \"FinalAnswer\" in actions:\n",
    "            content = actions[\"FinalAnswer\"]['parameters']['content']\n",
    "            print(\"Final Answer: \"+ str(content))\n",
    "            exitFlag = input(\"Do you want to exit? Type Y/y to exit...\")\n",
    "            if exitFlag.lower() == \"y\":\n",
    "                print('Thanks for chatting! Goodbye!')\n",
    "                break\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a113ed-09dc-4d20-ba76-baa879315c15",
   "metadata": {},
   "source": [
    "## CONCLUSION.\n",
    "#### Enter our conclusions here!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
