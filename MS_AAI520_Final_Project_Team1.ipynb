{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7846f45-e90c-44c2-8ad1-e1f8db4e3325",
   "metadata": {},
   "source": [
    "# UNIVERSITY OF SAN DIEGO - MS AAI\n",
    "## Natural Language Processing and Generative AI\n",
    "### Final Project - Team 1: Multi-Agent Financial Analysis System.\n",
    "#### By Manikandan Perumal & Israel Romero Olvera\n",
    "#### _________________________________________________\n",
    "#### The purpose of this final project is to build a real-world financial analysis system powered by agentic AI, with the abilities of reasoning, planning, and acting based on the user's prompt. It will coordinate multiple specialized LLM agents to handle complex financial tasks end-to-end.\n",
    "#### Our Agentic AI system was developed in a folder structure that can be found in our GitHub site: https://github.com/isralennon/AAI_520_Group_1/tree/main\n",
    "#### For delivery purposes we've condensed all the code into this document, structured the following way:\n",
    "#### 1. Tools - this section contains the code in file /modules/tools.py which will perform basic RAG connections.\n",
    "#### 2. Parser - this section contains the code in file /modules/parser.py, which provides basic functionality to parse data in JSON format.\n",
    "#### 3. Memory - this section contains the code in file /modules/memory.py that handles the storage of ongoing knowledge, to provide a robust and efficient functionality.\n",
    "#### 4. Agents - this section contains the code in file /modules/subagents.py, designed to host the definitions of the main Agent class as well as our specialized subagents - the team of agents available to the main orchestrator. We developed the following team of agents:\n",
    "#### - Orchestrator - the \"Manager\" of the Agents\n",
    "#### - News Researcher - the specialist of finding financial news, using FinnHub.\n",
    "#### - Market Researcher - the specialist of finding financial hard data like market trends, stock prices, etc.\n",
    "#### - Writer - the specialist of taking all the information and preparing a polished answer for the user\n",
    "#### 5. Main Orchestrator Agent - this section contains the code in file /modules/agent.py and has the definition for the orchestrator agent, which develops the strategy and coordinates all subagents.\n",
    "#### 6. Demo - this section contains the code in our main notebook, /main.ipynb - our implementation file where we execute all the above with demonstration purposes.\n",
    "#### _________________________________________________\n",
    "### 1. TOOLS.\n",
    "#### One of the four agent functions we'll implement is the usage of tools, which will be defined in this first section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5847078-4728-443e-9d7f-3a350066678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "#import modules.tools as tools\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import finnhub\n",
    "from typing import Callable\n",
    "from datetime import datetime, timedelta\n",
    "from google import genai\n",
    "import openai\n",
    "\n",
    "# For privacy reasons, we'll store our token keys on a .env file, which we'll load here:\n",
    "dotenv.load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "# First, we'll define a generic Tool class, which will serve as a structure for all of our tools\n",
    "class Tool:\n",
    "    def __init__(self, name, function, description, api=None): # This is the initialization method of the class\n",
    "        self.name = name # Placeholder for the name of the tool\n",
    "        self.function = function # Placeholder for the code of the tool's function\n",
    "        self.description = description # Placeholder for the description of the tool - very important since the agents will use this description to know what the tool does\n",
    "        self.api = api  # Placeholder for API details when needed\n",
    "        \n",
    "    def to_dict(self): # The structure of each class will always be a standard dictionary object that can be easily interpreted by the Agents\n",
    "        return {\n",
    "            \"name\": self.name,\n",
    "            \"description\": self.description,\n",
    "            \"api\": self.api\n",
    "        }\n",
    "    \n",
    "    def invoke(self, **kwargs): # This is the placeholder of the function for the tool, which will receive a variable number of parameters\n",
    "        print(f\"Invoking {self.name} with arguments {kwargs}\")\n",
    "        return self.function(**kwargs) # Returning the results of the function\n",
    "\n",
    "# Next, we'll declare each individual tool as a class, inheriting from the generic class Tool above\n",
    "class YahooFinance(Tool): # The first tool is YahooFinance, which will pull stock quotes for a given financial symbol, like AAPL for Apple\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"Yahoo Finance Stock Quote\", # Name of the tool\n",
    "            function=self.get_stock_quote_yahoo, # Pointing to the YahooFinance function below as this class's own function\n",
    "            description=\"Get the latest stock quote for a given symbol from Yahoo Finance.\", # Definition of the tool for our agents\n",
    "            api=\"\"\"{ \"\"symbol\": \"AAPL\"}\"\"\", # Parameter sample for the agent to use when it uses this class\n",
    "        )\n",
    "    def get_stock_quote_yahoo(self, symbol: str, step: str='') -> dict: # This is the function that pulls the stock using YahooFinance API\n",
    "        # Here we'll perform the call to YahooFinance to get the data from the specified symbol.\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        # Then, we'll use the 'fast_info' method, which pulls basic financial information, including the price.\n",
    "        try:\n",
    "            info = ticker.fast_info # Pulling the information and parsing it to return it\n",
    "            return {\n",
    "                \"symbol\": symbol,\n",
    "                \"last_price\": info[\"lastPrice\"],\n",
    "                \"day_high\": info[\"dayHigh\"],\n",
    "                \"day_low\": info[\"dayLow\"],\n",
    "                \"previous_close\": info[\"previousClose\"]\n",
    "            }\n",
    "        except Exception as e: # Should there be any errors, we will print the error message instead and return an empty dictionary\n",
    "            print(f\"Yahoo Finance API error: {e}\")\n",
    "            return {}\n",
    "#Now, we'll continue with the class that calls Financial Modeling Prep API\n",
    "class FMP(Tool):\n",
    "    def __init__(self,name:str,function:Callable=None,description:str=None,api:str=None,endPoint:str=None):\n",
    "        super().__init__(name=name,function=self.execute if function==None else function,description=description,api=api)\n",
    "        self.endpoint = endPoint if endPoint!=None else  os.getenv(\"FMP_Endpoint\") # It reads the endpoint from our .env file\n",
    "        self.apikey = os.getenv(\"FMP_API_KEY\") # It also reads the API key from our .env file\n",
    "    def execute(self, symbol: str) -> dict: # This is the function that pulls the stock data using FMP API\n",
    "        params = { #These are the parameters for the API call in a dictionary format\n",
    "            \"symbol\": symbol,\n",
    "            \"apikey\": self.apikey,\n",
    "            \"exchange\": \"NASDAQ\"\n",
    "        }\n",
    "        try: #Then we'll try to make the call to the API and return its formatted response as a JSON text\n",
    "            # print(f'Calling FMP API at endpoint: {self.endpoint} with params: {params}')\n",
    "            response=requests.get(self.endpoint, params=params)\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e: # Should there be any errors, we'll print the error message and return an empty dictionary\n",
    "            print(f'FMP API error: {e}')\n",
    "            return {}\n",
    "        \n",
    "class StockQuote(FMP):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"Stack Quote\", # Name of the tool\n",
    "            description=\"Get the latest stock quote for a given symbol from Stack Quote.\", # Definition of the tool for our agents\n",
    "            api=\"\"\"{ \"symbol\": \"AAPL\"}\"\"\", # Parameter sample for the agent to use when it uses this class\n",
    "            endPoint='https://financialmodelingprep.com/stable/quote' # It reads the endpoint from our .env file\n",
    "        )\n",
    "\n",
    "        \n",
    "class StockPriceChange(FMP):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"Stock Price Change\", # Name of the tool\n",
    "            description=\"Get the stock price change for a given symbol over the past.\", # Definition of the tool for our agents\n",
    "            api=\"\"\"{ \"symbol\": \"AAPL\", \"days\": 7}\"\"\", # Parameter sample for the agent to use when it uses this class\n",
    "            endPoint='https://financialmodelingprep.com/stable/stock-price-change' # It reads the endpoint from our .env file\n",
    "        )\n",
    "        \n",
    "class IncomeStatement(FMP):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"Income Statement\", # Name of the tool\n",
    "            description=\"Get the income statement for a given symbol from Financial Modeling Prep (FMP).\", # Definition of the tool for our agents\n",
    "            api=\"\"\"{ \"symbol\": \"AAPL\"}\"\"\", # Parameter sample for the agent to use when it uses this class\n",
    "            endPoint='https://financialmodelingprep.com/stable/income-statement' # It reads the endpoint from our .env file\n",
    "        )\n",
    "  \n",
    "class FinancialScore(FMP):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"Financial Score\", # Name of the tool\n",
    "            description=\"Get the financial score for a given symbol from Financial Modeling Prep (FMP).\", # Definition of the tool for our agents\n",
    "            api=\"\"\"{ \"symbol\": \"AAPL\"}\"\"\" ,# Parameter sample for the agent to use when it uses this class\n",
    "            endPoint='https://financialmodelingprep.com/stable/financial-scores' # It reads the endpoint from our .env file\n",
    "        )\n",
    "   \n",
    "        \n",
    "#We'll be using FinnHub as our News provider next\n",
    "class FinancialNews(Tool): \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"FinnHub News\", # Name of the tool\n",
    "            function=self.get_stock_quote_finnhub, # Pointing to the FinnHub function below as this class's own function\n",
    "            description=\"Get the latest financial news for a given symbol from FinnHub.\", # Definition of the tool for our agents\n",
    "            api=\"\"\"{ \"\"symbol\": \"AAPL\"}\"\"\" # Parameter sample for the agent to use when it uses this class\n",
    "        )\n",
    "    def get_stock_quote_finnhub(self, symbol: str, step: str='') -> dict: # This is the function that pulls the news data using FinnHub\n",
    "        FinnHubAPIKey = os.getenv(\"FINNHUB_API_KEY\") # Gets the API key from our .env file\n",
    "        # Next, we setup the client to perform calls:\n",
    "        finn_client = finnhub.Client(api_key=FinnHubAPIKey)\n",
    "\n",
    "        # Setting a time frame for the news, ending today and starting a week ago\n",
    "        end_date = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "        start_date = (datetime.today() - timedelta(days=7)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Now, we call the API, returning the news in the already pre-formatted dictionary structure.\n",
    "        try:\n",
    "            news= finn_client.company_news(symbol, _from=start_date, to=end_date)\n",
    "            if len(news)==0:\n",
    "                return {\"message\": f\"No news found for symbol {symbol} from {start_date} to {end_date}.\"}\n",
    "            top_news = sorted(news, key=lambda x: x['datetime'], reverse=True)[:5]\n",
    "            top_news_formatted = []\n",
    "            for item in top_news:\n",
    "                top_news_formatted.append({\n",
    "                    \"headline\": item.get(\"headline\"),\n",
    "                    \"summary\": item.get(\"summary\"),\n",
    "                    \"datetime\": datetime.fromtimestamp(item.get(\"datetime\")).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                })\n",
    "        \n",
    "            return {\n",
    "                \"symbol\": symbol,\n",
    "                \"news\": top_news_formatted  \n",
    "            }\n",
    "    \n",
    "        except Exception as e: # Should there be any errors, we'll print the error message and return an empty dictionary\n",
    "            print(f'Finnhub.io API error: {e}')\n",
    "            return {}\n",
    "\n",
    "class RecommendationTrends(Tool):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"FinnHub Recommendation Trends\", # Name of the tool\n",
    "            function=self.get_recommendation_trends, # Pointing to the FinnHub function below as this class's own function\n",
    "            description=\"Get the recommendation trends for a given symbol from FinnHub.\", # Definition of the tool for our agents\n",
    "            api=\"\"\"{ \"\"symbol\": \"AAPL\"}\"\"\" # Parameter sample for the agent to use when this class\n",
    "        )\n",
    "    def get_recommendation_trends(self, symbol: str) -> dict:\n",
    "        FinnHubAPIKey = os.getenv(\"FINNHUB_API_KEY\") # Gets the API key from our .env file\n",
    "        finn_client = finnhub.Client(api_key=FinnHubAPIKey)\n",
    "        try:\n",
    "            return finn_client.recommendation_trends(symbol)\n",
    "        except Exception as e: # Should there be any errors, we'll print the error message and return an empty dictionary\n",
    "            print(f'Finnhub.io API error: {e}')\n",
    "            return {}\n",
    "        \n",
    "class EarningSurprise(Tool):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"FinnHub Earning Surprise\", # Name of the tool\n",
    "            function=self.get_earning_surprise, # Pointing to the FinnHub function below as this class's own function\n",
    "            description=\"Get the earning surprise for a given symbol from FinnHub.\", # Definition of the tool for our agents\n",
    "            api=\"\"\"{ \"\"symbol\": \"AAPL\"}\"\"\" # Parameter sample for the agent to use when this class\n",
    "        )\n",
    "    def get_earning_surprise(self, symbol: str) -> dict:\n",
    "        FinnHubAPIKey = os.getenv(\"FINNHUB_API_KEY\") # Gets the API key from our .env file\n",
    "        finn_client = finnhub.Client(api_key=FinnHubAPIKey)\n",
    "        try:\n",
    "            return finn_client.company_earnings(symbol,limit=5)\n",
    "        except Exception as e: # Should there be any errors, we'll print the error message and return an empty dictionary\n",
    "            print(f'Finnhub.io API error: {e}')\n",
    "            return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadd7b2a-b7e4-45df-8551-153c0d0da84b",
   "metadata": {},
   "source": [
    "### 2. PARSER\n",
    "#### One of the workflow patterns our agents will do is routing, meaning our main agent will coordinate with subagents. To accomplish this communication, we need a \"common language\", which in this case will be JSON. This section defines the functions to implement the JSON parsing functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa5fdb39-7ca7-4dca-8fb9-6173fa06dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll define first a Parser abstract class\n",
    "class Parser:\n",
    "    def parse(self, response): # This is the placeholder of the default method for this class\n",
    "        # Here's the returned value, which will be a dictionary with an Action value, and a list of dynamic parameters.\n",
    "        return {\"action\": \"FinalAnswer\", \"parameters\": {}}\n",
    "# Next, we'll define an XML parser, which inherits from our abstract class Parser.    \n",
    "class XmlParser(Parser):\n",
    "    def parse(self, response):\n",
    "        # A parser that extracts XML tags from the response.\n",
    "        # For example, it looks for <InvokeTool>{\"symbol\": \"AAPL\", \"step\": \"financials\"}</InvokeTool>\n",
    "        # or <FinalAnswer>answer</FinalAnswer>.\n",
    "        # Returns : a dict with action and parameters. Example:\n",
    "        # {\n",
    "        #    \"action\": \"InvokeTool\",\n",
    "        #    \"parameters\": {\n",
    "        #        \"symbol\": \"AAPL\",\n",
    "        #        \"step\": \"financials\"\n",
    "        #    }\n",
    "        #}\n",
    "        import re\n",
    "        pattern = r'<(\\w+)>(.*?)</\\1>' # Defining the regular expression for XML structure\n",
    "        matches = re.findall(pattern, response) # Identifying all matches of XML\n",
    "        if matches: # When there are XML matches, we'll separate them and parse their contents\n",
    "            action, content = matches[0]\n",
    "            content = content.strip()\n",
    "            contentJson = {}\n",
    "            try:\n",
    "                import json\n",
    "                contentJson = json.loads(content) # Once parsed, we'll reformat them to JSON\n",
    "            except:\n",
    "                contentJson = {\"content\": content} # If the content is not valid, we'll return the error message with the invalid content text\n",
    "                return {\"action\": action, \"parameters\": contentJson, \"error\": \"Content is not valid JSON\"}\n",
    "            return {\"action\": action, \"parameters\": contentJson} # If it was valid, we return the parsed content in JSON format\n",
    "        return {\"action\": \"FinalAnswer\", \"parameters\": {}} #If there wasn't any XML to begin with, we just return an empty list of parameters\n",
    "    # Next, we have a specialized parsing for our agent's functionality that will interpret the actions in XML tags and encode them as a list of dictionaries\n",
    "    def parse_all(self, response):\n",
    "        import re\n",
    "        pattern = r'<(\\w+)>(.*?)</\\1>' # Defining the regular expression for XML structure\n",
    "        matches = re.findall(pattern, response) # Identifying all matches of XML\n",
    "        results = [] # Preparing an empty array for the results\n",
    "        for action, content in matches: # For each detected action (if any),\n",
    "            content = content.strip()   # we'll parse its contents\n",
    "            contentJson = {}\n",
    "            try: # Then, we'll try to convert it to JSON format\n",
    "                import json\n",
    "                contentJson = json.loads(content)\n",
    "            except: # Should any errors occur, we'll return the error message as part of the response\n",
    "                contentJson = {\"content\": content}\n",
    "                results.append({\"action\": action, \"parameters\": contentJson, \"error\": \"Content is not valid JSON\"})\n",
    "                continue\n",
    "            results.append({\"action\": action, \"parameters\": contentJson}) # If everything's fine, we'll return the parsed JSON content\n",
    "        if not results:\n",
    "            results.append({\"action\": \"FinalAnswer\", \"parameters\": {}}) # If there were no actions, we'll return an empty dictionary\n",
    "        return results  \n",
    "    \n",
    "    def parseTags(self, response):\n",
    "        '''Agent response parser to extract all TAGS.\n",
    "            Returns a dictionary with tag names as keys and tag values as values.\n",
    "        '''\n",
    "        import re\n",
    "        pattern = r'<(\\w+)>(.*?)</\\1>'\n",
    "        matches = re.findall(pattern, response)\n",
    "        result = {}\n",
    "        for tag, value in matches:\n",
    "                result[tag.lower()] = value.strip() \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b0e958-92da-4165-acd4-d541e967c259",
   "metadata": {},
   "source": [
    "### 3. MEMORY.\n",
    "#### Another feature of our agent is learning, which means the agent must remember information as it gets prompted to refine their answers and keep getting more knowledgeable as it gets used. The functions that perform such learning are defined in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef5315f5-f806-4c34-87f7-f4187f6baa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "# We're creating a class called MemorySystem with all the learning functionality\n",
    "class MemorySystem:\n",
    "    # This class stores insights and lessons from previous analyses to improve future runs.\n",
    "    def __init__(self, memory_file='agent_memory.pkl'): # It will store the learned data into the specified file, or the default file name.\n",
    "        self.memory_file = memory_file\n",
    "        self.stock_insights = {}\n",
    "        self.news_insights = {}\n",
    "        self.load_memory()\n",
    "    \n",
    "    def load_memory(self): # Should there be a previous file in existence, it can load it using this function\n",
    "        try:\n",
    "            if os.path.exists(self.memory_file): # It will look for the file name specified in the instance of this class\n",
    "                with open(self.memory_file, 'rb') as f: # If it exists, it will attempt to open it\n",
    "                    memory_data = pickle.load(f) # Then, it will load the data into memory\n",
    "                    self.stock_insights = memory_data.get('stock_insights', {}) # separating stock insights,\n",
    "                    self.news_insights = memory_data.get('news_insights', {}) # market news insights,\n",
    "            else: # Should there be no prior file, it will start fresh\n",
    "                print(\"No memory file found. Starting with empty memory.\")\n",
    "        except Exception as e: # Should there be an error while loading the file, it will start fresh as well\n",
    "            print(f\"Error loading memory: {e}\")\n",
    "            print(\"Starting with empty memory.\")\n",
    "    \n",
    "    def save_memory(self): # This method will save the memory in the file in a structured manner\n",
    "        try:\n",
    "            memory_data = {\n",
    "                'stock_insights': self.stock_insights, # It will save all stock insights currently provided,\n",
    "                'news_insights': self.news_insights # followed by news insights\n",
    "            }\n",
    "            with open(self.memory_file, 'wb') as f: # It will first open the file name specified in the instance of this class\n",
    "                pickle.dump(memory_data, f) # and then write in it the contents of the memory_data dictionary\n",
    "            print(\"Memory saved successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving memory: {e}\") # Should there be any errors saving, it will print out the error\n",
    "    \n",
    "    def add_stock_insight(self, symbol, insight, timestamp=None): # With this method, we'll add knowledge classified as stock insights\n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now().isoformat() # If no timestamp is specified, we'll initialize the current time stamp\n",
    "        \n",
    "        if symbol not in self.stock_insights: # If the current symbol (financial company) is not in previous insights, we'll add it\n",
    "            self.stock_insights[symbol] = []\n",
    "        \n",
    "        self.stock_insights[symbol].append({ # Finally, we encode the insight with its timestamp in the stock_insights dictionary of this class\n",
    "            'insight': insight,\n",
    "            'timestamp': timestamp\n",
    "        })\n",
    "        self.save_memory() # And we save the memory right away\n",
    "    \n",
    "    def add_market_news(self,symbol, news_item, timestamp=None): # This method adds market news insights for a given symbol\n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.now().isoformat() # If no timestamp is specified, we'll initialize the current time stamp\n",
    "\n",
    "        if symbol not in self.news_insights: # If the current symbol (financial company) is not in previous insights, we'll add it\n",
    "            self.news_insights[symbol] = []\n",
    "\n",
    "        self.news_insights[symbol].append({ # Finally, we encode the news item with its timestamp in the news_insights dictionary of this class\n",
    "            'news_item': news_item,\n",
    "            'timestamp': timestamp\n",
    "        })\n",
    "        self.save_memory() # And we save the memory right away\n",
    "\n",
    "    def get_stock_insights(self, symbol): # This method retrieves all stock insights for a given symbol\n",
    "        results=self.stock_insights.get(symbol, [])\n",
    "        if not results:\n",
    "            print(f\"No insights found for symbol {symbol}.\")\n",
    "            return []\n",
    "        if results:\n",
    "            filtered_results = []\n",
    "            for result in results:\n",
    "                # if the timestamp is older than 7 days, we can choose to ignore it\n",
    "                timestamp = datetime.fromisoformat(result['timestamp'])\n",
    "                if (datetime.now() - timestamp).days > 7:\n",
    "                    continue\n",
    "                filtered_results.append(result)\n",
    "        return filtered_results\n",
    "\n",
    "    def get_news_insights(self, symbol): # This method retrieves all market news insights for a given symbol\n",
    "        results=self.news_insights.get(symbol, [])\n",
    "        if not results:\n",
    "            print(f\"No news insights found for symbol {symbol}.\")\n",
    "            return []\n",
    "        if results:\n",
    "            filtered_results = []\n",
    "            for result in results:\n",
    "                # if the timestamp is older than 2 days, we can choose to ignore it\n",
    "                timestamp = datetime.fromisoformat(result['timestamp'])\n",
    "                if (datetime.now() - timestamp).days > 2:\n",
    "                    continue\n",
    "                filtered_results.append(result)\n",
    "        return filtered_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf287589-30f8-4c56-a61c-175eeaf9af11",
   "metadata": {},
   "source": [
    "### 4. AGENTS\n",
    "#### For our routing workflow, along with communication also comes specialization and tool usage: a team of agents that will collaborate, coordinated by the main orchestrator agent. That's what we'll define in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13a923fc-91cd-40c0-aeb6-55eb20d0bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we'll initialize the Google GenAI and OpenAI\n",
    "from google import genai\n",
    "import openai\n",
    "#Make sure to load the environmental variables\n",
    "dotenv.load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "\n",
    "# Downloading necessary libraries and functionality - uncomment when needed.\n",
    "#nltk.download('vader_lexicon')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "class Agent: # This will be our base class for all our agents\n",
    "    def __init__(self, name, role, system_prompt, model, generate_response, agents=None, tools=None, memory_system=None, parser=None, debug=0): # This is the initialization method of the Agent class\n",
    "        self.name = name # Placeholder for the name of the tool\n",
    "        self.model = model # Placeholder for the LLM model\n",
    "        self.role = role # Placeholder for the role of this agent\n",
    "        self.system_prompt = system_prompt # Placeholder for the system prompt that defines this agent\n",
    "        self.memory_system = memory_system # Placeholder for the memory object for this agent - it could be None, so the agent would start without knowledge\n",
    "        self.parser = parser  # Placeholder for API details when needed\n",
    "        self.generate_response = generate_response # Placeholder for the generate response method\n",
    "        self.agents = agents \n",
    "        self.tools = tools # Placeholder for the tools passed on to this agent, which should be a list\n",
    "        self.conversation_history = [] # Initializing a blank conversation history\n",
    "        self.max_history_length = 10 # Initializing a default max number of history length\n",
    "\n",
    "        self.prompt_template = (\n",
    "            \"You are {agent_name}, an AI agent. Use the following tools as needed:\\n\"\n",
    "            \"{tools}\\n\"\n",
    "            \"Conversation history:\\n\"\n",
    "            \"{history}\\n\"\n",
    "            \"Current input: {input}\\n\"\n",
    "            \"Respond appropriately.\"\n",
    "        )\n",
    "        self.initialize_client() #Initializing the LLM client\n",
    "        self.debug = debug #Setting the debug local variable, used to print certain validation statements when set to 1\n",
    "    #We want our Agent class to support multiple LLMs, so this function will help initialize its internal client dynamically.\n",
    "    def initialize_client(self):\n",
    "        #For GPT models\n",
    "        if \"gpt\" in self.model.lower(): \n",
    "            self.client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        #For Gemini models\n",
    "        elif \"gemini\" in self.model.lower():\n",
    "            self.client = genai.Client()\n",
    "    def to_dict(self): # The structure of each class will always be a standard dictionary object that can be easily interpreted by the Agents\n",
    "        return {\n",
    "            \"name\": self.name,\n",
    "            \"description\": self.description,\n",
    "            \"api\": self.api\n",
    "        }\n",
    "    def register_tool(self, tool): #This function helps register tools that the agent will have access to.\n",
    "        self.tools.append(tool) \n",
    "    def remember(self, message): #This function enables the agent to remember a message in its conversation history\n",
    "        self.conversation_history.append(message)\n",
    "        if len(self.conversation_history) > self.max_history_length:\n",
    "            self.conversation_history.pop(0)\n",
    "    def call_llm(self, input_prompt): #This is the generic call to LLM that agents can use. They may have a different version if needs are unique\n",
    "        try:\n",
    "            #For GPT models\n",
    "            if \"gpt\" in self.model.lower(): \n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": input_prompt}\n",
    "                    ],\n",
    "                    max_tokens=300,\n",
    "                    temperature=0.7\n",
    "                )\n",
    "                result = response.choices[0].message.content\n",
    "            #For Gemini models\n",
    "            elif \"gemini\" in self.model.lower():\n",
    "                prompt = self.system_prompt\n",
    "                prompt += \"\\n\" + input_prompt\n",
    "                response = self.client.models.generate_content(\n",
    "                    model=self.model, contents=str(prompt)\n",
    "                )\n",
    "                result = response.text\n",
    "            #print(f\"{self.name} using model '{self.model}': {result[:60]}...\")\n",
    "            #print(result)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            if self.debug == 1:\n",
    "                print(f\" API failed for {self.name} using model '{self.model}': {e}\")\n",
    "            return f\"Mock response from {self.name} with model '{self.model}': {input_prompt[:50]}...\"\n",
    "    def generate_response(self, **kwargs): # This is the placeholder of the generative function for the agent, which will receive a variable number of parameters\n",
    "        if self.debug == 1:\n",
    "            print(f\"Invoking {self.name} generative response function with arguments {kwargs}\")\n",
    "        return self.generate_response(**kwargs) # Returning the results of the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed17b1-9690-4054-8131-025b22fe39fb",
   "metadata": {},
   "source": [
    "#### Next, let's define some Sub-agents that will inherit from the class above.\n",
    "#### We'll start with the Market Research agent, capable of finding hard-financial data like stock quotes or market trends using some of the financial tools declared at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b97db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketResearchAgent(Agent):\n",
    "    def __init__(self, model=\"gemini-2.5-flash\", debug=0):\n",
    "        name=\"Market Research Agent\"\n",
    "        model=model\n",
    "        role=\"Market Research Agent specialized in financial data analysis and market trends\"\n",
    "        system_prompt=f\"\"\"You are a Market Research Agent specialized in financial data analysis and market trends.\n",
    "         Your role is to assist users by providing accurate and up-to-date financial information, stock quotes, market trends, and insights based on the latest data available from various financial APIs and tools.\n",
    "\n",
    "         Based on the data retrieved from the tools at your disposal, provide comprehensive answers to user queries related to stock performance, market analysis, and financial news.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.memory_system=MemorySystem()\n",
    "        super().__init__(name=name,system_prompt=system_prompt,model=model,generate_response=self.generate_response,role=role,agents=None,tools=None,memory_system=self.memory_system,parser=None, debug=debug) \n",
    "    \n",
    "    def generate_response(self, **kwargs): # This is the placeholder of the generative function for the agent, which will receive a variable number of parameters\n",
    "        if self.debug == 1:\n",
    "            print(f\"Invoking {self.name} generative response function with arguments {kwargs}\")\n",
    "        input_prompt=kwargs.get(\"prompt\",[])\n",
    "        try:\n",
    "            #For GPT models\n",
    "            if \"gpt\" in self.model.lower(): \n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": input_prompt}\n",
    "                    ],\n",
    "                    #messages=input_prompt,\n",
    "                    max_tokens=300,\n",
    "                    temperature=0.7\n",
    "                )\n",
    "                result = response.choices[0].message.content\n",
    "            #For Gemini models\n",
    "            elif \"gemini\" in self.model.lower():\n",
    "                response = self.client.models.generate_content(\n",
    "                    model=self.model, contents=str(input_prompt)\n",
    "                )\n",
    "                result = response.text\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            if self.debug == 1:\n",
    "                print(f\" API failed for {self.name} using model '{self.model}': {e}\")\n",
    "            return f\"Mock response from {self.name} with model '{self.model}': {input_prompt[:50]}...\"\n",
    "\n",
    "    def getMarketSummary(self,symbol:str  ) -> str:\n",
    "        prompt=f\"\"\"Provide a comprehensive market summary for the stock symbol: {symbol}. \n",
    "                Include recent performance, key financial metrics, and any notable news or trends affecting the stock.\n",
    "                Use data from Yahoo Finance, Financial Modeling Prep, and FinnHub to inform your summary.\n",
    "                Format the response in a clear and concise manner suitable for a financial report.\"\"\"\n",
    "        insights = self.memory_system.get_stock_insights(symbol)\n",
    "        if insights:\n",
    "            if self.debug == 1:\n",
    "                print(f\"Using cached insight for symbol {symbol}.\")\n",
    "            return insights[-1]['insight']\n",
    "        else:\n",
    "            tools_list=[FinancialScore(),IncomeStatement(),StockQuote(),StockPriceChange()]\n",
    "            for tool in tools_list:\n",
    "                tool_response=tool.invoke(symbol=symbol)\n",
    "                prompt+=f\"\\nData from {tool.name}: {tool_response}\"\n",
    "            response=self.generate_response(prompt=prompt)\n",
    "            self.memory_system.add_stock_insight(symbol, response,timestamp=datetime.now().isoformat())\n",
    "        return response  \n",
    "    \n",
    "    def  processUserInput(self, user_input: str) -> str:\n",
    "        tags=self.getEntities(user_input=user_input)\n",
    "        if \"symbol\" in tags:\n",
    "            marketSummary=self.getMarketSummary(symbol=tags.get(\"symbol\"))\n",
    "        prompt=f\"\"\"Based on the {marketSummary} Analyze the following user input\n",
    "                and provide a short answer for the user query.\n",
    "                Rules:\n",
    "                - If the user input is related to stock performance, provide insights based on the market summary.\n",
    "                - If the user input is unrelated to financial markets, respond with \"I'm sorry, I can only assist with financial market-related queries.\"\n",
    "                - Keep the response concise and relevant to the user's query.\n",
    "                - Use a professional and informative tone suitable for financial discussions.\n",
    "                - Limit the response to 150 words.\n",
    "\n",
    "                User Input: \"{user_input}\"\n",
    "\n",
    "\n",
    "                Answer:\n",
    "                \"\"\",\n",
    "        response=self.generate_response(prompt=prompt)\n",
    "        return response\n",
    "\n",
    "    def getEntities(self, user_input: str) -> str:\n",
    "        prompt=f\"\"\"Determine entities the following user input related to financial markets and stock analysis:\n",
    "                if the input contains Apple Inc, return SYMBOL as AAPL\n",
    "                if the input contains Microsoft Corporation, return SYMBOL as MSFT\n",
    "                User Input: \"{user_input}\n",
    "                Extracted Entities:\n",
    "                    <SYMBOL>...</SYMBOL>\n",
    "                    <EXCHANGE>...</EXCHANGE><INDUSTRY>...</INDUSTRY>  \"\"\"\n",
    "        response=self.generate_response(prompt=prompt)\n",
    "        if self.debug == 1:\n",
    "            print(f'Response: {response}')\n",
    "        parser=XmlParser()\n",
    "        parsed_response=parser.parseTags(response)\n",
    "        return parsed_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba108b-b298-4412-a752-a17970a6d742",
   "metadata": {},
   "source": [
    "#### Then, we'll define a Market Sentiment Agent, which will pull financial news using some of the financial tools above, and classify their sentiment, which will be helpful for the research and analsys of the company in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb24a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketSentimentAgent(Agent):\n",
    "    def __init__(self, model=\"gemini-2.5-flash\", debug=0):\n",
    "        name=\"Market News Sentiment Agent\"\n",
    "        model=model\n",
    "        role=\"Market News Sentiment Agent specialized in financial news sentiment analysis\"\n",
    "        system_prompt=f\"\"\"You are a Market Sentiment Agent specialized in financial news sentiment analysis.\n",
    "         Your role is to assist users by analyzing the sentiment of financial news articles and providing insights based on the emotional tone of the content.\n",
    "\n",
    "         Based on the news data retrieved from FinnHub, provide comprehensive sentiment analysis to help users understand market mood and potential impacts on stock performance.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.memory_system=MemorySystem()\n",
    "        super().__init__(name=name,system_prompt=system_prompt,model=model,generate_response=self.generate_response,role=role,agents=None,tools=None,memory_system=self.memory_system,parser=None, debug=debug)\n",
    "        \n",
    "    def generate_response(self, **kwargs): # This is the placeholder of the generative function for the agent, which will receive a variable number of parameters\n",
    "        if self.debug==1:\n",
    "            print(f\"Invoking {self.name} generative response function with arguments {kwargs}\")\n",
    "        input_prompt=kwargs.get(\"prompt\",[])\n",
    "        try:\n",
    "            #For GPT models\n",
    "            if \"gpt\" in self.model.lower(): \n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=input_prompt,\n",
    "                    max_tokens=300,\n",
    "                    temperature=0.7\n",
    "                )\n",
    "                result = response.choices[0].message.content\n",
    "            #For Gemini models\n",
    "            elif \"gemini\" in self.model.lower():\n",
    "                response = self.client.models.generate_content(\n",
    "                    model=self.model, contents=str(input_prompt)\n",
    "                )\n",
    "                result = response.text\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            if self.debug==1:\n",
    "                print(f\" API failed for {self.name} using model '{self.model}': {e}\")\n",
    "            return f\"Mock response from {self.name} with model '{self.model}': {input_prompt[:50]}...\"\n",
    "        \n",
    "    def getNewsSummary(self,symbol:str  ) -> str:\n",
    "            prompt=f\"\"\"Provide a comprehensive news summary for the stock symbol: {symbol}.\n",
    "                    Include recent news articles, key events, and any notable trends affecting the stock.\n",
    "                    Use data from FinnHub and other news sources to inform your summary.\n",
    "                    Format the response in a clear and concise manner suitable for a financial report.\"\"\"\n",
    "            insights = self.memory_system.get_news_insights(symbol)\n",
    "            if insights:\n",
    "                if self.debug==1:\n",
    "                    print(f\"Using cached insight for symbol {symbol}.\")\n",
    "                return insights[-1]['news_item']\n",
    "            else:\n",
    "                tools_list=[FinancialNews(),RecommendationTrends(),EarningSurprise()]\n",
    "                for tool in tools_list:\n",
    "                    tool_response=tool.invoke(symbol=symbol)\n",
    "                    prompt+=f\"\\nData from {tool.name}: {tool_response}\"\n",
    "                response=self.generate_response(prompt=prompt)\n",
    "                self.memory_system.add_market_news(symbol, response,timestamp=datetime.now().isoformat())\n",
    "            return response\n",
    "        \n",
    "    def processUserInput(self, user_input: str) -> str:\n",
    "        if self.debug==1:\n",
    "            print(\"-\" * 50)\n",
    "            print(f'{self.name}\" received input: {user_input}')\n",
    "            print(\"-\" * 50)\n",
    "        tags=self.getEntities(user_input=user_input)\n",
    "        if \"symbol\" in tags:\n",
    "            newsSummary=self.getNewsSummary(symbol=tags.get(\"symbol\"))\n",
    "        prompt=f\"\"\"Based on the {newsSummary} Analyze the following user input\n",
    "                and provide a short answer for the user query.\n",
    "                Rules:\n",
    "                - If the user input is related to financial news sentiment, provide insights based on the news summary.\n",
    "                - If the user input is unrelated to financial markets, respond with \"I'm sorry, I can only assist with financial market-related queries.\"\n",
    "                - Keep the response concise and relevant to the user's query.\n",
    "                - Use a professional and informative tone suitable for financial discussions.\n",
    "                - Limit the response to 150 words.\n",
    "\n",
    "                User Input: \"{user_input}\"\n",
    "\n",
    "\n",
    "                Answer:\n",
    "                \"\"\",\n",
    "        response=self.generate_response(prompt=prompt)\n",
    "        return response\n",
    "    def getEntities(self, user_input: str) -> str:\n",
    "        prompt=f\"\"\"Determine entities the following user input related to financial markets and stock analysis:\n",
    "                if the input contains Apple Inc, return SYMBOL as AAPL\n",
    "                if the input contains Microsoft Corporation, return SYMBOL as MSFT\n",
    "                User Input: \"{user_input}\n",
    "                Extracted Entities:\n",
    "                    <SYMBOL>...</SYMBOL>\n",
    "                    <EXCHANGE>...</EXCHANGE><INDUSTRY>...</INDUSTRY>  \"\"\"\n",
    "        response=self.generate_response(prompt=prompt)\n",
    "        parser=XmlParser()\n",
    "        parsed_response=parser.parseTags(response)\n",
    "        return parsed_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d0b9f-ecd8-4d6c-a103-acd402e022ef",
   "metadata": {},
   "source": [
    "#### Then, we'll define a Writer agent in charge of providing a polished and structured answer with the researched data provided by the other agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ac90380-12c0-4734-8642-c0c0445c230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WriterAgent(Agent):\n",
    "    # This agent takes the results of other agents (like news or market research) and creates a professional report that will be returned to the Orchestrator for the Final Response to the user.\n",
    "    def __init__ (self, model=\"gpt-3.5-turbo\", agents=None, memory_system=None, debug=0):\n",
    "        super().__init__(\n",
    "            name=\"Writer\", #Name of the Writer class\n",
    "            role=\"Writer Agent specialized in polished Financial Content\", #Role of this class\n",
    "            system_prompt=(\n",
    "                \"You are Writer, an AI agent part of an agents team. Your role is a professional \"\n",
    "                \"financial report writer, capable of taking financial news \"\n",
    "                \"or financial information provided by the Orchestrator and \"\n",
    "                \"preparing a 2–3 paragraph report that provides a clear final \"\n",
    "                \"answer to the user.\"\n",
    "                \"Here are some guidelines for you:\"\n",
    "                \"Start your answers giving a positive message like 'Great question', 'Excellent question', or similar.\"\n",
    "                \"Focus on answering the user's question.\"\n",
    "                \"When recommendations are requested, only provide guidance and highlight pros and cons.\"\n",
    "                \"The news or financial information you're receiving came from other agents in the team, so never refer to it as 'the data provided'.\"\n",
    "            ),            \n",
    "            model = model,\n",
    "            generate_response = self.generate_response,\n",
    "            memory_system = memory_system,\n",
    "            debug=debug\n",
    "        )\n",
    "    def generate_response(self, input_prompt):\n",
    "        result = self.call_llm(input_prompt)\n",
    "        return result\n",
    "    def processUserInput(self, input_prompt: str) -> str:\n",
    "        prompt=input_prompt\n",
    "        response=self.generate_response(input_prompt=prompt)\n",
    "        return response    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d208600-b43d-424f-b54d-7ee6f97c1257",
   "metadata": {},
   "source": [
    "### 5. MAIN ORCHESTRATOR AGENT.\n",
    "#### This is the section where we define the orchestrator agent, which performs the interpretation of the user's prompt, prepares a plan, calls the subagents as needed, and prepares the final answer to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8fa6bcc-d542-4354-80bc-95ad0e9cf6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrchestratorAgent(Agent):\n",
    "    def __init__(self, model, agents=None, memory=None, parser=None, debug=0):\n",
    "        self.agents = agents\n",
    "        #self.agents_description = \"\\n\".join([f\"- {agent.name}: {agent.role}\" for agent in self.agents.items()])\n",
    "        self.agents_description = \"\"\n",
    "        for agent in self.agents:\n",
    "            self.agents_description += f'\\n- {agent.name}: {agent.role}'\n",
    "\n",
    "        system_prompt = f'''\n",
    "          You are the leading AI agent for the following team of agents:\n",
    "            {self.agents_description}\n",
    "\n",
    "            You do not generate a response directly to the user, but instead you'll coordinate the agents team by generating a list of tasks for them to do following the Agent Usage guidelines.\n",
    "            \n",
    "            ### Agent Usage Guidelines:\n",
    "\n",
    "            1. Do not respond to the current input directly. Instead, create a plan to call the research agents in your team to pull the necessary data.\n",
    "            2. Convert that plan into a list of calls for your specialized agents (except for the Writer Agent) using an XML structure with the tag \"<SpecializedAgent>\" in the following format:\n",
    "            <SpecializedAgent>{{\"agentName\": \"Market Research Agent\", \"user_input\": \"Your specific query here\"}}</SpecializedAgent>\n",
    "            3. The writer agent will be called separately to finalize the response. Exclude from your thinking process.\n",
    "            \n",
    "            ### Other TAGs you can include in your plan:\n",
    "            -  For thinking, you must wrap your thoughts in <Thought> and </Thought> tags.\n",
    "            -  For final answers, you must wrap your answer in <FinalAnswer> and </FinalAnswer> tags.\n",
    "            -  If you need users to provide more information, you must wrap your request in <RequestMoreInfo> and </RequestMoreInfo> tags.\n",
    "           \n",
    "            ### Instructions for using the tools:\n",
    "            You should only use the information returned by the Agents listed above, never try to get information independently.\n",
    "        '''\n",
    "        system_prompt = system_prompt.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        # We also need to declare a parser\n",
    "        if parser==None:\n",
    "            parser = XmlParser()\n",
    "\n",
    "        super().__init__(\n",
    "            name = \"Orchestrator Agent\", #Name of the Orchestrator class\n",
    "            role = \"Orchestrator Agent that manages tool usage and conversation flow\",\n",
    "            system_prompt = system_prompt,\n",
    "            model = model,\n",
    "            generate_response = self.generate_response,\n",
    "            memory_system = memory,\n",
    "            agents = agents,\n",
    "            parser = parser,\n",
    "            debug = debug # Storing the variable debug, used for printing messages when set to 1\n",
    "        )\n",
    "        self.conversation_history = []\n",
    "            # Limit for conversation history\n",
    "        # print(f\"Prompt Template: {self.system_prompt}\")\n",
    "        self.prompt_template = (\n",
    "            f\"{self.system_prompt}\\n\"\n",
    "            \"Conversation history:\\n\"\n",
    "            \"{history}\\n\"\n",
    "            \"Current input: {input}\\n\"\n",
    "        )\n",
    "        self.parser = parser\n",
    "        self.initialize_client()\n",
    "\n",
    "    def remember(self, message):\n",
    "        self.conversation_history.append(message)\n",
    "        if len(self.conversation_history) > self.max_history_length:\n",
    "            self.conversation_history.pop(0)\n",
    "    \n",
    "    def generate_response(self, input_prompt):\n",
    "        history_text = \"\\n\".join(self.conversation_history)\n",
    "        #print(\"Conversation History: \")\n",
    "        #print(history_text)\n",
    "        response = \"\"\n",
    "        prompt = self.prompt_template.format(\n",
    "            history=history_text,\n",
    "            input=input_prompt\n",
    "        )\n",
    "        if self.debug==1:\n",
    "            print(f\"Orchestrator Prompt: {prompt}\")\n",
    "        try:\n",
    "            #For GPT models\n",
    "            if \"gpt\" in self.model.lower(): \n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    #messages=input_prompt,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": prompt}\n",
    "                    ],\n",
    "                    max_tokens=300,\n",
    "                    temperature=0.7\n",
    "                )\n",
    "                result = response.choices[0].message.content\n",
    "            #For Gemini models\n",
    "            elif \"gemini\" in self.model.lower():\n",
    "                response = self.client.models.generate_content(\n",
    "                    model=self.model, contents=str(input_prompt)\n",
    "                )\n",
    "                result = response.text\n",
    "            self.remember(f\"User: {input_prompt}\")\n",
    "            self.remember(f\"{self.name}: {response}\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            if self.debug==1:\n",
    "                print(f\" API failed for {self.name} using model '{self.model}': {e}\")\n",
    "            return f\"Mock response from {self.name} with model '{self.model}': {input_prompt[:50]}...\"\n",
    "        return response\n",
    "    \n",
    "\n",
    "    def get_specialist_opinion(self, agentName, user_input):\n",
    "        '''Agent Orchestrator can call other agents to get their opinion on specific user inputs.'''\n",
    "        MyAgentsTeam = {MyMarketResearcher, MyNewsResearcher, MyWriter}\n",
    "        for agent in self.agents:\n",
    "            if agent.name == agentName:\n",
    "                return agent.processUserInput(user_input)\n",
    "        return f\"Agent {agentName} not found.\"\n",
    "        \n",
    "    \n",
    "    def reAct(self, user_input:str)-> str:\n",
    "        # Here is the the logic to parse the response for Agents usage\n",
    "        # and store the results.\n",
    "        parsed_response = \"\"\n",
    "        #Preparing a temporary repository for agent responses\n",
    "        temp_agent_response = \"\"\n",
    "        temp_agent_response_count = 0\n",
    "        #We also initialize the content variable we'll pass to the writer\n",
    "        content_for_writer = f'Current user prompt: {user_input}'\n",
    "        if self.parser and self.agents:\n",
    "            response = self.generate_response(user_input)\n",
    "            parsed_response = self.parser.parse_all(response) ## parsed response is a dict {\"InvokeTool\": \"tool_name\", \"parameters\": {...}} or {\"FinalAnswer\": \"answer\"} or {\"RequestMoreInfo\": \"info\"}\n",
    "            if self.debug==1:\n",
    "                print(\"*\" * 50)\n",
    "                print(f'Raw actions from Orchestrator: {response}')\n",
    "                print(\"*\" * 50)\n",
    "                print(\"*\" * 50)\n",
    "                print(f'Actions list from Orchestrator: {parsed_response}')\n",
    "                print(\"*\" * 50)\n",
    "            system_message = f\"System: {response}\"\n",
    "            self.remember(system_message)\n",
    "            self.conversation_history.append(system_message)\n",
    "            '''\n",
    "            parsed_response= {\n",
    "            \"action\": \"InvokeTool\",\n",
    "            \"parameters\": {\n",
    "                \"symbol\": \"AAPL\",\n",
    "                \"step\": \"financials\"\n",
    "                }\n",
    "            }\n",
    "            '''\n",
    "            # Next, we'll loop through all the actions in the plan to execute one at a time.\n",
    "            for plan_item in parsed_response:\n",
    "                action = plan_item.get(\"action\")\n",
    "                if self.debug==1:\n",
    "                    print(f\"Orchestrator Action: {action}\")\n",
    "                if action == \"SpecializedAgent\":\n",
    "                    agent_name = plan_item[\"parameters\"].get(\"agentName\")\n",
    "                    user_input_for_agent = plan_item[\"parameters\"].get(\"user_input\")\n",
    "                    if self.debug==1:\n",
    "                        print(\"-\" * 50)\n",
    "                        print(f'Orchestrator calling {agent_name} with prompt \"{user_input_for_agent}\"')\n",
    "                        print(\"-\" * 50)\n",
    "                    agent_response = self.get_specialist_opinion(agent_name, user_input_for_agent)\n",
    "                    temp_agent_response = f\"Agent {agent_name} Response: {agent_response}\"\n",
    "                    self.remember(temp_agent_response)\n",
    "                    self.conversation_history.append(temp_agent_response)\n",
    "                    content_for_writer += f'\\n\\n{temp_agent_response}'\n",
    "                    # Generate a new response based on the agent result\n",
    "                    #response = self.generate_response(f\"Agent {agent_name} Response: {agent_response}\")\n",
    "                    #parsed_response = self.parser.parse(response)   \n",
    "                    temp_agent_response_count += 1\n",
    "                elif action == \"FinalAnswer\" or action == \"RequestMoreInfo\" or action == \"NeedApproval\":\n",
    "                    print(f\"Orchestrator Final Response: {response}\")\n",
    "                    return parsed_response.get(\"content\")\n",
    "                elif action == \"Thought\":\n",
    "                    continue\n",
    "                else:\n",
    "                    return f\"I'm not sure how to proceed. Could you please clarify? - selected action: {action}\"\n",
    "            #Once the loop of actions is completed, we'll pass the information gathered by all research agents down to our writer\n",
    "            #user_input_for_agent = \n",
    "            response = self.get_specialist_opinion('Writer', content_for_writer)\n",
    "        else:\n",
    "            parsed_response = \"Error: no parser or sub agents found!\"\n",
    "            print('Parser:')\n",
    "            print(self.parser)\n",
    "            print('Agents:')\n",
    "            print(self.agents)\n",
    "            response = parsed_response\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b7fae3d-16cf-4e77-9fd0-40f33e0ad6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Excellent question! Evaluating whether it\\'s a good time to invest in Tesla (TSLA) stock today involves weighing several dynamic factors. On one hand, Tesla has demonstrated remarkable long-term growth, with its stock price surging by over 99% in the past year and more than 200% over five years. It also shows strong short-term momentum, reflecting a daily increase of 2.46% and steady gains over the last month. Analyst sentiment, while mixed, still leans towards a net positive outlook, with a significant number of \\'Strong Buy\\' and \\'Buy\\' recommendations, underpinning sustained revenue growth and robust financial health.\\n\\nHowever, potential investors should also consider the considerable caution surrounding the stock. Tesla is currently at a \"make-or-break point\" as it approaches its Q3 2025 earnings report next week, which is crucial given three consecutive earnings misses in previous quarters. There are growing concerns regarding margin compression, with the Net Income Margin significantly declining, and persistent high EV costs potentially impacting demand. The stock\\'s high P/E ratio of 215.35x indicates a premium valuation, suggesting that substantial future growth is already factored into its current price, making it highly sensitive to future performance and market sentiment.\\n\\nTherefore, the decision to buy Tesla stock today comes with both compelling opportunities and significant risks. For investors with a high risk tolerance and a belief in Tesla\\'s ability to overcome current challenges and meet ambitious growth expectations, the current momentum and long-term track record might be appealing. Conversely, those seeking lower risk might find the upcoming earnings report, high valuation, and margin pressures warrant a more cautious \"wait-and-see\" approach, especially considering the broader market volatility. Your investment strategy should align with your individual financial goals and risk profile.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can use \"gpt-3.5-turbo\" or \"gemini-2.5-flash\", #Uncomment if using Google GenAI\n",
    "\n",
    "#Let's declare our sub agent instances first.\n",
    "MyMarketResearcher = MarketResearchAgent(model=\"gemini-2.5-flash\")\n",
    "MyNewsResearcher = MarketSentimentAgent(model=\"gemini-2.5-flash\")\n",
    "MyWriter = WriterAgent(model=\"gemini-2.5-flash\")\n",
    "\n",
    "#We put all of our sub agents together as a list of objects\n",
    "MyAgentsTeam = {MyMarketResearcher, MyNewsResearcher, MyWriter}\n",
    "\n",
    "#Now, we declare our main orchestrator agent instance.\n",
    "MyOrchestrator = OrchestratorAgent(model=\"gpt-3.5-turbo\", agents=MyAgentsTeam)\n",
    "sample_prompt = \"Based on the latest news and stock prices, it is a good time to buy Tesla stock today?\"\n",
    "\n",
    "MyOrchestrator.reAct(sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae3de4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No insights found for symbol AAPL.\n",
      "Invoking Financial Score with arguments {'symbol': 'AAPL'}\n",
      "Invoking Income Statement with arguments {'symbol': 'AAPL'}\n",
      "Invoking Stack Quote with arguments {'symbol': 'AAPL'}\n",
      "Invoking Stock Price Change with arguments {'symbol': 'AAPL'}\n",
      "Memory saved successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Excellent question! Determining the \"best price\" for a stock like Apple Inc. (AAPL) is highly dependent on an individual investor\\'s financial goals, strategy, and risk tolerance, as market valuations are dynamic and personal. From a recent market perspective, Apple closed at $252.29, showing a daily gain and strong overall financial health. The company reported impressive Fiscal Year 2024 results, including $391.04 Billion in revenue and $93.74 Billion in net income, with a diluted EPS of $6.08, underscoring robust profitability and a significant revenue rebound. Technically, the stock is also demonstrating a bullish trend, trading above its 50-day and 200-day moving averages, indicating positive momentum.\\n\\nWhen considering a \\'best price\\' for investment, these strong fundamentals and positive market momentum present a compelling case, suggesting the company is performing well and has investor confidence. However, a prudent investor would also weigh these positives against broader market conditions, the stock\\'s valuation relative to its growth prospects and industry peers, and their personal risk tolerance. While current information indicates a financially sound company with a positive market outlook, the optimal entry point ultimately aligns with an individual\\'s specific investment thesis and assessment of future market dynamics, rather than a single definitive price.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyOrchestrator.reAct(\"What is best price for Apple inc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abea2e1e-d811-44cb-83eb-1afd0d66f720",
   "metadata": {},
   "source": [
    "### 6. DEMO.\n",
    "#### This is the final section, which contains the implementation of the entire system using all elements above for a quick demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a4fff4-e92e-4b1f-a976-497ffa407111",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = systemPrompt\n",
    "userText =\"\"\n",
    "continueFlag = False\n",
    "exitFlag = \"\"\n",
    "debug = False\n",
    "while userText.lower() != \"exit\" or exitFlag.lower() != \"y\":\n",
    "    if not continueFlag:\n",
    "        userText = input(\"User: \")\n",
    "        if userText.lower() == \"exit\":\n",
    "            break\n",
    "        prompt += \"\\n User:\"+ userText\n",
    "        continueFlag = False\n",
    "    if debug:\n",
    "        print('Prompt: ')\n",
    "        print(prompt)\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\", contents=prompt\n",
    "    )\n",
    "    if debug:\n",
    "        print('Model response: ')\n",
    "        print(response.text)\n",
    "    prompt = prompt + response.text\n",
    "    actions = parser.parse_all(response.text.replace('\\n', ' '))\n",
    "    if debug:\n",
    "        print('Actions: ')\n",
    "        print(actions)\n",
    "    if not actions:\n",
    "        continue\n",
    "    if len(actions) >= 1:\n",
    "        actions = { action['action']: action for action in actions if action.get(\"action\",\"\") != \"Final Answer\" }\n",
    "        if \"NeedApproval\" in actions:\n",
    "            actions.pop(\"NeedApproval\")\n",
    "            if \"InvokeTool\" in actions:\n",
    "                #result=input(\"Need to Call \" + actions[\"InvokeTool\"].get(\"name\",\"\") + \" Y/y to continue...)\")\n",
    "                result=input(\"Need to Call \" + actions[\"InvokeTool\"]['parameters']['name'] + \". Type Y/y to continue...)\")\n",
    "            else:\n",
    "                result=input(\"Need User Approval Y/y to continue...)\")\n",
    "            if result.lower() != \"y\":\n",
    "                print(\"Exiting...\")\n",
    "                break\n",
    "            actions[\"NeedApproval\"] = {\"action\":\"NeedApproval\", \"content\":\"User approved to continue.\"}\n",
    "            prompt += \"\\n User:\"+ actions[\"NeedApproval\"].get(\"content\",\"\")\n",
    "        if 'InvokeTool' in actions:\n",
    "            action = actions[\"InvokeTool\"]\n",
    "            tools_name = action[\"parameters\"][\"name\"]\n",
    "            tool_params = action[\"parameters\"][\"api\"]\n",
    "            result = executionMap[tools_name].invoke(**json.loads(tool_params))\n",
    "            actions[\"Tool result\"] = {\"action\":\"Tool result\", \"content\":result}\n",
    "            prompt += \"\\n User:\"+ str(result)\n",
    "            continueFlag = True\n",
    "        if \"FinalAnswer\" in actions:\n",
    "            content = actions[\"FinalAnswer\"]['parameters']['content']\n",
    "            print(\"Final Answer: \"+ str(content))\n",
    "            exitFlag = input(\"Do you want to exit? Type Y/y to exit...\")\n",
    "            if exitFlag.lower() == \"y\":\n",
    "                print('Thanks for chatting! Goodbye!')\n",
    "                break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7364802c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orchestrator Response: Excellent question! Determining the \"best price\" for a stock like Apple Inc. (AAPL) is subjective and depends heavily on an individual investor's financial goals, risk tolerance, and investment horizon. There isn't a single universally \"best\" price, as what's optimal for one investor might not be for another. The latest reported stock price for Apple Inc. (AAPL) is $252.29 as of October 15, 2024, reflecting a daily increase of +1.96%.\n",
      "\n",
      "When evaluating Apple, it's helpful to consider its underlying financial performance. For fiscal year 2024, the company reported robust revenue of $391.04 Billion, a strong gross profit of $180.68 Billion, and a net income of $93.74 Billion, resulting in a diluted EPS of $6.08. These figures indicate a healthy and profitable enterprise, with a modest revenue rebound, consistent earnings per share, and continued significant investment in research and development. These positive financial indicators suggest a resilient company, but whether the current market price aligns with an individual's \"best price\" depends on their personal valuation model and market outlook.\n",
      "\n",
      "As an AI, I cannot provide personalized investment recommendations or declare a specific price as \"best\" for your individual situation. However, understanding the current market price and the strong financial fundamentals can help inform your decision-making. Investors often consider factors such as future growth prospects, market sentiment, comparative valuations, and their own investment strategy when determining what constitutes a good entry or exit point for a stock.\n",
      "No insights found for symbol GOOGL.\n",
      "Invoking Financial Score with arguments {'symbol': 'GOOGL'}\n",
      "Invoking Income Statement with arguments {'symbol': 'GOOGL'}\n",
      "Invoking Stack Quote with arguments {'symbol': 'GOOGL'}\n",
      "Invoking Stock Price Change with arguments {'symbol': 'GOOGL'}\n",
      "Memory saved successfully.\n",
      "Orchestrator Response: Excellent question! Comparing Apple Inc. (AAPL) and Alphabet Inc. (GOOGL) offers valuable insights into two of the technology sector's giants. While their current stock prices are remarkably close, hovering around the $250-$253 range, a deeper look into their financial metrics reveals distinct characteristics that can inform an investor's perspective.\n",
      "\n",
      "For fiscal year 2024, Apple reported robust revenue of $391.04 Billion and a net income of $93.74 Billion, resulting in a diluted EPS of $6.08. These figures highlight Apple as a healthy and profitable enterprise, demonstrating a modest revenue rebound, consistent earnings per share, and significant investment in research and development. In contrast, Alphabet Inc. shows strong projected growth for FY2204, with anticipated revenue of $350.02 Billion, a projected net income of $100.12 Billion, and a projected diluted EPS of $8.04. Alphabet's financial health is further underscored by an Altman Z-Score of 15.44, indicating excellent financial stability, and a Piotroski F-Score of 6, suggesting a solid financial position. This comparison shows Apple with higher current revenue, while Alphabet is projected to slightly surpass Apple in net income and diluted EPS for the same period, alongside strong indicators of financial stability and growth.\n",
      "\n",
      "Ultimately, determining which company might align better with an individual's portfolio depends on their specific investment goals and risk appetite. Both Apple and Alphabet present strong financial fundamentals and are leaders in their respective markets. Apple demonstrates resilience and consistent profitability with a focus on product innovation and services, while Alphabet exhibits strong projected growth across its revenue, net income, and EPS, coupled with exceptional financial health indicators. Investors typically weigh these factors, along with future growth prospects, market sentiment, and their own investment horizon, when deciding between such financially sound enterprises.\n",
      "Exiting the financial market assistant. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "## Create a beautiful chatbot interface using HTML display\n",
    "## Initialize the chatbot with beautiful styling\n",
    "clear_output(wait=True)\n",
    "display_chat_header()\n",
    "\n",
    "## Create a conversation loop with user input and orchestrator response\n",
    "conversation_history = []\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"💬 Your question: \")\n",
    "        \n",
    "        # Display user message with beautiful styling\n",
    "        display_user_message(user_input)\n",
    "        conversation_history.append(f\"User: {user_input}\")\n",
    "        \n",
    "        if user_input.lower() == 'exit':\n",
    "            display_status_message(\"👋 Exiting the financial market assistant. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Show typing indicator while processing\n",
    "        display_typing_indicator()\n",
    "        time.sleep(1)  # Brief pause for realistic effect\n",
    "        \n",
    "        # Get response from orchestrator\n",
    "        response = MyOrchestrator.reAct(user_input)  # Pass just the user input, not the full history\n",
    "        conversation_history.append(f\"Orchestrator: {response}\")\n",
    "        \n",
    "        # Clear typing indicator and display bot response\n",
    "        clear_output(wait=True)\n",
    "        display_chat_header()\n",
    "        \n",
    "        # Redisplay recent conversation\n",
    "        recent_history = conversation_history[-6:]  # Show last 3 exchanges\n",
    "        for i in range(0, len(recent_history), 2):\n",
    "            if i < len(recent_history):\n",
    "                # Display user message\n",
    "                user_msg = recent_history[i].replace(\"User: \", \"\")\n",
    "                display_user_message(user_msg)\n",
    "            if i + 1 < len(recent_history):\n",
    "                # Display bot message\n",
    "                bot_msg = recent_history[i + 1].replace(\"Orchestrator: \", \"\")\n",
    "                display_bot_message(bot_msg)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        display_status_message(\"👋 Chat interrupted. Goodbye!\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        display_bot_message(f\"❌ Sorry, I encountered an error: {str(e)}\")\n",
    "        display_status_message(\"Please try asking your question again.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1958deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for beautiful HTML display in Jupyter notebook\n",
    "from IPython.display import HTML, display, clear_output\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39c6eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSS styles for beautiful chatbot interface\n",
    "chatbot_css = \"\"\"\n",
    "<style>\n",
    ".chat-container {\n",
    "    max-width: 800px;\n",
    "    margin: 0 auto;\n",
    "    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "    border-radius: 20px;\n",
    "    padding: 20px;\n",
    "    box-shadow: 0 10px 30px rgba(0,0,0,0.3);\n",
    "}\n",
    "\n",
    ".chat-header {\n",
    "    text-align: center;\n",
    "    color: white;\n",
    "    font-size: 24px;\n",
    "    font-weight: bold;\n",
    "    margin-bottom: 20px;\n",
    "    text-shadow: 2px 2px 4px rgba(0,0,0,0.5);\n",
    "}\n",
    "\n",
    ".message {\n",
    "    margin: 15px 0;\n",
    "    display: flex;\n",
    "    align-items: flex-start;\n",
    "}\n",
    "\n",
    ".user-message {\n",
    "    justify-content: flex-end;\n",
    "}\n",
    "\n",
    ".bot-message {\n",
    "    justify-content: flex-start;\n",
    "}\n",
    "\n",
    ".message-bubble {\n",
    "    max-width: 70%;\n",
    "    padding: 15px 20px;\n",
    "    border-radius: 20px;\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.15);\n",
    "    position: relative;\n",
    "    line-height: 1.4;\n",
    "}\n",
    "\n",
    ".user-bubble {\n",
    "    background: linear-gradient(135deg, #36d1dc 0%, #5b86e5 100%);\n",
    "    color: white;\n",
    "    margin-left: 30px;\n",
    "}\n",
    "\n",
    ".bot-bubble {\n",
    "    background: white;\n",
    "    color: #333;\n",
    "    margin-right: 30px;\n",
    "    border: 1px solid #e0e0e0;\n",
    "}\n",
    "\n",
    ".message-avatar {\n",
    "    width: 40px;\n",
    "    height: 40px;\n",
    "    border-radius: 50%;\n",
    "    margin: 0 10px;\n",
    "    display: flex;\n",
    "    align-items: center;\n",
    "    justify-content: center;\n",
    "    font-weight: bold;\n",
    "    color: white;\n",
    "    font-size: 16px;\n",
    "}\n",
    "\n",
    ".user-avatar {\n",
    "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "}\n",
    "\n",
    ".bot-avatar {\n",
    "    background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);\n",
    "}\n",
    "\n",
    ".timestamp {\n",
    "    font-size: 11px;\n",
    "    color: rgba(255,255,255,0.7);\n",
    "    margin-top: 5px;\n",
    "    text-align: right;\n",
    "}\n",
    "\n",
    ".bot-timestamp {\n",
    "    color: #999;\n",
    "    text-align: left;\n",
    "}\n",
    "\n",
    ".typing-indicator {\n",
    "    display: flex;\n",
    "    align-items: center;\n",
    "    justify-content: flex-start;\n",
    "    margin: 15px 0;\n",
    "}\n",
    "\n",
    ".typing-bubble {\n",
    "    background: white;\n",
    "    padding: 15px 20px;\n",
    "    border-radius: 20px;\n",
    "    margin-right: 30px;\n",
    "    margin-left: 50px;\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.15);\n",
    "}\n",
    "\n",
    ".typing-dots {\n",
    "    display: flex;\n",
    "    gap: 4px;\n",
    "}\n",
    "\n",
    ".dot {\n",
    "    width: 8px;\n",
    "    height: 8px;\n",
    "    background: #999;\n",
    "    border-radius: 50%;\n",
    "    animation: typing 1.4s infinite ease-in-out;\n",
    "}\n",
    "\n",
    ".dot:nth-child(1) { animation-delay: -0.32s; }\n",
    ".dot:nth-child(2) { animation-delay: -0.16s; }\n",
    "\n",
    "@keyframes typing {\n",
    "    0%, 80%, 100% { transform: scale(0.8); opacity: 0.5; }\n",
    "    40% { transform: scale(1); opacity: 1; }\n",
    "}\n",
    "\n",
    ".input-container {\n",
    "    margin-top: 20px;\n",
    "    text-align: center;\n",
    "}\n",
    "\n",
    ".status-message {\n",
    "    text-align: center;\n",
    "    color: white;\n",
    "    font-style: italic;\n",
    "    margin: 10px 0;\n",
    "    opacity: 0.8;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "# Helper functions for chatbot display\n",
    "def display_chat_header():\n",
    "    \"\"\"Display the chatbot header\"\"\"\n",
    "    header_html = f\"\"\"\n",
    "    {chatbot_css}\n",
    "    <div class=\"chat-container\">\n",
    "        <div class=\"chat-header\">\n",
    "            💰 CapitalMind Financial Assistant 🤖\n",
    "        </div>\n",
    "        <div class=\"status-message\">\n",
    "            Welcome! Ask me anything about financial markets and stocks.\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(header_html))\n",
    "\n",
    "def display_user_message(message):\n",
    "    \"\"\"Display user message with styling\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%H:%M\")\n",
    "    user_html = f\"\"\"\n",
    "    <div class=\"chat-container\">\n",
    "        <div class=\"message user-message\">\n",
    "            <div class=\"message-bubble user-bubble\">\n",
    "                {message}\n",
    "                <div class=\"timestamp\">{timestamp}</div>\n",
    "            </div>\n",
    "            <div class=\"message-avatar user-avatar\">👤</div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(user_html))\n",
    "\n",
    "def display_typing_indicator():\n",
    "    \"\"\"Display typing indicator\"\"\"\n",
    "    typing_html = f\"\"\"\n",
    "    <div class=\"chat-container\">\n",
    "        <div class=\"typing-indicator\">\n",
    "            <div class=\"message-avatar bot-avatar\">🤖</div>\n",
    "            <div class=\"typing-bubble\">\n",
    "                <div class=\"typing-dots\">\n",
    "                    <div class=\"dot\"></div>\n",
    "                    <div class=\"dot\"></div>\n",
    "                    <div class=\"dot\"></div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(typing_html))\n",
    "\n",
    "def display_bot_message(message):\n",
    "    \"\"\"Display bot message with styling\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%H:%M\")\n",
    "    # Format the message with line breaks for better readability\n",
    "    formatted_message = message.replace('\\n', '<br>')\n",
    "    \n",
    "    bot_html = f\"\"\"\n",
    "    <div class=\"chat-container\">\n",
    "        <div class=\"message bot-message\">\n",
    "            <div class=\"message-avatar bot-avatar\">🤖</div>\n",
    "            <div class=\"message-bubble bot-bubble\">\n",
    "                {formatted_message}\n",
    "                <div class=\"timestamp bot-timestamp\">{timestamp}</div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(bot_html))\n",
    "\n",
    "def display_status_message(message):\n",
    "    \"\"\"Display status message\"\"\"\n",
    "    status_html = f\"\"\"\n",
    "    <div class=\"chat-container\">\n",
    "        <div class=\"status-message\">\n",
    "            {message}\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(status_html))\n",
    "\n",
    "def clear_typing_indicator():\n",
    "    \"\"\"Clear the typing indicator\"\"\"\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17cc747d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "<style>\n",
       ".chat-container {\n",
       "    max-width: 800px;\n",
       "    margin: 0 auto;\n",
       "    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
       "    border-radius: 20px;\n",
       "    padding: 20px;\n",
       "    box-shadow: 0 10px 30px rgba(0,0,0,0.3);\n",
       "}\n",
       "\n",
       ".chat-header {\n",
       "    text-align: center;\n",
       "    color: white;\n",
       "    font-size: 24px;\n",
       "    font-weight: bold;\n",
       "    margin-bottom: 20px;\n",
       "    text-shadow: 2px 2px 4px rgba(0,0,0,0.5);\n",
       "}\n",
       "\n",
       ".message {\n",
       "    margin: 15px 0;\n",
       "    display: flex;\n",
       "    align-items: flex-start;\n",
       "}\n",
       "\n",
       ".user-message {\n",
       "    justify-content: flex-end;\n",
       "}\n",
       "\n",
       ".bot-message {\n",
       "    justify-content: flex-start;\n",
       "}\n",
       "\n",
       ".message-bubble {\n",
       "    max-width: 70%;\n",
       "    padding: 15px 20px;\n",
       "    border-radius: 20px;\n",
       "    box-shadow: 0 4px 12px rgba(0,0,0,0.15);\n",
       "    position: relative;\n",
       "    line-height: 1.4;\n",
       "}\n",
       "\n",
       ".user-bubble {\n",
       "    background: linear-gradient(135deg, #36d1dc 0%, #5b86e5 100%);\n",
       "    color: white;\n",
       "    margin-left: 30px;\n",
       "}\n",
       "\n",
       ".bot-bubble {\n",
       "    background: white;\n",
       "    color: #333;\n",
       "    margin-right: 30px;\n",
       "    border: 1px solid #e0e0e0;\n",
       "}\n",
       "\n",
       ".message-avatar {\n",
       "    width: 40px;\n",
       "    height: 40px;\n",
       "    border-radius: 50%;\n",
       "    margin: 0 10px;\n",
       "    display: flex;\n",
       "    align-items: center;\n",
       "    justify-content: center;\n",
       "    font-weight: bold;\n",
       "    color: white;\n",
       "    font-size: 16px;\n",
       "}\n",
       "\n",
       ".user-avatar {\n",
       "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
       "}\n",
       "\n",
       ".bot-avatar {\n",
       "    background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);\n",
       "}\n",
       "\n",
       ".timestamp {\n",
       "    font-size: 11px;\n",
       "    color: rgba(255,255,255,0.7);\n",
       "    margin-top: 5px;\n",
       "    text-align: right;\n",
       "}\n",
       "\n",
       ".bot-timestamp {\n",
       "    color: #999;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".typing-indicator {\n",
       "    display: flex;\n",
       "    align-items: center;\n",
       "    justify-content: flex-start;\n",
       "    margin: 15px 0;\n",
       "}\n",
       "\n",
       ".typing-bubble {\n",
       "    background: white;\n",
       "    padding: 15px 20px;\n",
       "    border-radius: 20px;\n",
       "    margin-right: 30px;\n",
       "    margin-left: 50px;\n",
       "    box-shadow: 0 4px 12px rgba(0,0,0,0.15);\n",
       "}\n",
       "\n",
       ".typing-dots {\n",
       "    display: flex;\n",
       "    gap: 4px;\n",
       "}\n",
       "\n",
       ".dot {\n",
       "    width: 8px;\n",
       "    height: 8px;\n",
       "    background: #999;\n",
       "    border-radius: 50%;\n",
       "    animation: typing 1.4s infinite ease-in-out;\n",
       "}\n",
       "\n",
       ".dot:nth-child(1) { animation-delay: -0.32s; }\n",
       ".dot:nth-child(2) { animation-delay: -0.16s; }\n",
       "\n",
       "@keyframes typing {\n",
       "    0%, 80%, 100% { transform: scale(0.8); opacity: 0.5; }\n",
       "    40% { transform: scale(1); opacity: 1; }\n",
       "}\n",
       "\n",
       ".input-container {\n",
       "    margin-top: 20px;\n",
       "    text-align: center;\n",
       "}\n",
       "\n",
       ".status-message {\n",
       "    text-align: center;\n",
       "    color: white;\n",
       "    font-style: italic;\n",
       "    margin: 10px 0;\n",
       "    opacity: 0.8;\n",
       "}\n",
       "</style>\n",
       "\n",
       "    <div class=\"chat-container\">\n",
       "        <div class=\"chat-header\">\n",
       "            💰 CapitalMind Financial Assistant 🤖\n",
       "        </div>\n",
       "        <div class=\"status-message\">\n",
       "            Welcome! Ask me anything about financial markets and stocks.\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"chat-container\">\n",
       "        <div class=\"message user-message\">\n",
       "            <div class=\"message-bubble user-bubble\">\n",
       "                What's the current stock price of Apple Inc?\n",
       "                <div class=\"timestamp\">15:14</div>\n",
       "            </div>\n",
       "            <div class=\"message-avatar user-avatar\">👤</div>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"chat-container\">\n",
       "        <div class=\"message bot-message\">\n",
       "            <div class=\"message-avatar bot-avatar\">🤖</div>\n",
       "            <div class=\"message-bubble bot-bubble\">\n",
       "                Great question! Based on the latest market data for Apple Inc (AAPL), I can provide you with comprehensive stock information including current price, day high/low, and recent performance trends. Let me gather that information for you...\n",
       "                <div class=\"timestamp bot-timestamp\">15:14</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"chat-container\">\n",
       "        <div class=\"message user-message\">\n",
       "            <div class=\"message-bubble user-bubble\">\n",
       "                Is it a good time to buy Tesla stock?\n",
       "                <div class=\"timestamp\">15:14</div>\n",
       "            </div>\n",
       "            <div class=\"message-avatar user-avatar\">👤</div>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"chat-container\">\n",
       "        <div class=\"message bot-message\">\n",
       "            <div class=\"message-avatar bot-avatar\">🤖</div>\n",
       "            <div class=\"message-bubble bot-bubble\">\n",
       "                Excellent question! To provide you with accurate investment guidance for Tesla (TSLA), I'll analyze the current market conditions, recent news sentiment, financial metrics, and recommendation trends. <br><br>Based on my analysis, here are the key factors to consider:<br><br>• Current market performance and volatility<br>• Recent earnings and financial health<br>• Industry trends and competitive positioning<br>• Analyst recommendations and price targets<br><br>Please note that this is for informational purposes only and not financial advice.\n",
       "                <div class=\"timestamp bot-timestamp\">15:14</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demo of the beautiful chatbot interface\n",
    "# Let's show what the interface looks like with sample messages\n",
    "\n",
    "# Display the header\n",
    "display_chat_header()\n",
    "\n",
    "# Show a sample user message\n",
    "display_user_message(\"What's the current stock price of Apple Inc?\")\n",
    "\n",
    "# Show typing indicator briefly\n",
    "display_typing_indicator()\n",
    "time.sleep(2)\n",
    "\n",
    "# Clear and redisplay with bot response\n",
    "clear_output(wait=True)\n",
    "display_chat_header()\n",
    "display_user_message(\"What's the current stock price of Apple Inc?\")\n",
    "display_bot_message(\"Great question! Based on the latest market data for Apple Inc (AAPL), I can provide you with comprehensive stock information including current price, day high/low, and recent performance trends. Let me gather that information for you...\")\n",
    "\n",
    "# Show another exchange\n",
    "display_user_message(\"Is it a good time to buy Tesla stock?\")\n",
    "display_bot_message(\"Excellent question! To provide you with accurate investment guidance for Tesla (TSLA), I'll analyze the current market conditions, recent news sentiment, financial metrics, and recommendation trends. \\n\\nBased on my analysis, here are the key factors to consider:\\n\\n• Current market performance and volatility\\n• Recent earnings and financial health\\n• Industry trends and competitive positioning\\n• Analyst recommendations and price targets\\n\\nPlease note that this is for informational purposes only and not financial advice.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb74221",
   "metadata": {},
   "source": [
    "## 🎨 Beautiful Chatbot Interface\n",
    "\n",
    "The conversation loop above has been enhanced with a beautiful, modern chatbot interface that includes:\n",
    "\n",
    "### ✨ Features:\n",
    "- **Gradient Background**: Beautiful blue-purple gradient container\n",
    "- **Chat Bubbles**: Distinct styling for user (blue) and bot (white) messages\n",
    "- **Avatars**: User (👤) and bot (🤖) avatars for easy identification\n",
    "- **Timestamps**: Time stamps for each message\n",
    "- **Typing Indicator**: Animated dots showing when the bot is \"thinking\"\n",
    "- **Responsive Design**: Clean, modern layout that looks professional\n",
    "- **Error Handling**: Graceful error messages with styling\n",
    "- **Message History**: Shows recent conversation context\n",
    "\n",
    "### 🎯 How to Use:\n",
    "1. **Run the import cell** above to load HTML display libraries\n",
    "2. **Run the CSS and helper functions cell** to define the styling\n",
    "3. **Run the main conversation loop** to start chatting with the beautiful interface\n",
    "4. **Type your financial questions** and see the responses in beautiful chat bubbles\n",
    "5. **Type 'exit'** to end the conversation gracefully\n",
    "\n",
    "### 🚀 Example Questions to Try:\n",
    "- \"What's the current stock price of Apple Inc?\"\n",
    "- \"Is it a good time to buy Tesla stock?\"\n",
    "- \"Give me news about Microsoft Corporation\"\n",
    "- \"What's the financial score for Amazon?\"\n",
    "\n",
    "The interface will automatically format all messages with beautiful styling, making your financial AI assistant look professional and engaging!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a113ed-09dc-4d20-ba76-baa879315c15",
   "metadata": {},
   "source": [
    "## CONCLUSION.\n",
    "#### Enter our conclusions here!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
